{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691555f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8cd21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb3243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43428</th>\n",
       "      <td>41505.0</td>\n",
       "      <td>-16.526507</td>\n",
       "      <td>8.584972</td>\n",
       "      <td>-18.649853</td>\n",
       "      <td>9.505594</td>\n",
       "      <td>-13.793819</td>\n",
       "      <td>-2.832404</td>\n",
       "      <td>-16.701694</td>\n",
       "      <td>7.517344</td>\n",
       "      <td>-8.507059</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190739</td>\n",
       "      <td>-1.127670</td>\n",
       "      <td>-2.358579</td>\n",
       "      <td>0.673461</td>\n",
       "      <td>-1.413700</td>\n",
       "      <td>-0.462762</td>\n",
       "      <td>-2.018575</td>\n",
       "      <td>-1.042804</td>\n",
       "      <td>364.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49906</th>\n",
       "      <td>44261.0</td>\n",
       "      <td>0.339812</td>\n",
       "      <td>-2.743745</td>\n",
       "      <td>-0.134070</td>\n",
       "      <td>-1.385729</td>\n",
       "      <td>-1.451413</td>\n",
       "      <td>1.015887</td>\n",
       "      <td>-0.524379</td>\n",
       "      <td>0.224060</td>\n",
       "      <td>0.899746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213436</td>\n",
       "      <td>-0.942525</td>\n",
       "      <td>-0.526819</td>\n",
       "      <td>-1.156992</td>\n",
       "      <td>0.311211</td>\n",
       "      <td>-0.746647</td>\n",
       "      <td>0.040996</td>\n",
       "      <td>0.102038</td>\n",
       "      <td>520.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29474</th>\n",
       "      <td>35484.0</td>\n",
       "      <td>1.399590</td>\n",
       "      <td>-0.590701</td>\n",
       "      <td>0.168619</td>\n",
       "      <td>-1.029950</td>\n",
       "      <td>-0.539806</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>-0.712567</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>-0.971747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102398</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>-0.166639</td>\n",
       "      <td>-0.810250</td>\n",
       "      <td>0.505083</td>\n",
       "      <td>-0.232340</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276481</th>\n",
       "      <td>167123.0</td>\n",
       "      <td>-0.432071</td>\n",
       "      <td>1.647895</td>\n",
       "      <td>-1.669361</td>\n",
       "      <td>-0.349504</td>\n",
       "      <td>0.785785</td>\n",
       "      <td>-0.630647</td>\n",
       "      <td>0.276990</td>\n",
       "      <td>0.586025</td>\n",
       "      <td>-0.484715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358932</td>\n",
       "      <td>0.873663</td>\n",
       "      <td>-0.178642</td>\n",
       "      <td>-0.017171</td>\n",
       "      <td>-0.207392</td>\n",
       "      <td>-0.157756</td>\n",
       "      <td>-0.237386</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278846</th>\n",
       "      <td>168473.0</td>\n",
       "      <td>2.014160</td>\n",
       "      <td>-0.137394</td>\n",
       "      <td>-1.015839</td>\n",
       "      <td>0.327269</td>\n",
       "      <td>-0.182179</td>\n",
       "      <td>-0.956571</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>-0.160746</td>\n",
       "      <td>0.363241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238644</td>\n",
       "      <td>-0.616400</td>\n",
       "      <td>0.347045</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>-0.360196</td>\n",
       "      <td>0.174730</td>\n",
       "      <td>-0.078043</td>\n",
       "      <td>-0.070571</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>75618.0</td>\n",
       "      <td>1.173488</td>\n",
       "      <td>0.100792</td>\n",
       "      <td>0.490512</td>\n",
       "      <td>0.461596</td>\n",
       "      <td>-0.296377</td>\n",
       "      <td>-0.213165</td>\n",
       "      <td>-0.165254</td>\n",
       "      <td>0.119221</td>\n",
       "      <td>-0.114199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186027</td>\n",
       "      <td>-0.574283</td>\n",
       "      <td>0.161405</td>\n",
       "      <td>-0.006140</td>\n",
       "      <td>0.091444</td>\n",
       "      <td>0.109235</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>159000.0</td>\n",
       "      <td>-0.775981</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>-1.142399</td>\n",
       "      <td>-1.241113</td>\n",
       "      <td>1.940358</td>\n",
       "      <td>3.912076</td>\n",
       "      <td>-0.466107</td>\n",
       "      <td>1.360620</td>\n",
       "      <td>0.400697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037078</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>0.682820</td>\n",
       "      <td>-1.635109</td>\n",
       "      <td>-0.770941</td>\n",
       "      <td>0.066006</td>\n",
       "      <td>0.137056</td>\n",
       "      <td>89.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>79795.0</td>\n",
       "      <td>-0.146609</td>\n",
       "      <td>0.992946</td>\n",
       "      <td>1.524591</td>\n",
       "      <td>0.485774</td>\n",
       "      <td>0.349308</td>\n",
       "      <td>-0.815198</td>\n",
       "      <td>1.076640</td>\n",
       "      <td>-0.395316</td>\n",
       "      <td>-0.491303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052649</td>\n",
       "      <td>0.354089</td>\n",
       "      <td>-0.291198</td>\n",
       "      <td>0.402849</td>\n",
       "      <td>0.237383</td>\n",
       "      <td>-0.398467</td>\n",
       "      <td>-0.121139</td>\n",
       "      <td>-0.196195</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>87931.0</td>\n",
       "      <td>-2.948638</td>\n",
       "      <td>2.354849</td>\n",
       "      <td>-2.521201</td>\n",
       "      <td>-3.798905</td>\n",
       "      <td>1.866302</td>\n",
       "      <td>2.727695</td>\n",
       "      <td>-0.471769</td>\n",
       "      <td>2.217537</td>\n",
       "      <td>0.580199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332759</td>\n",
       "      <td>-1.047514</td>\n",
       "      <td>0.143326</td>\n",
       "      <td>0.678869</td>\n",
       "      <td>0.319710</td>\n",
       "      <td>0.426309</td>\n",
       "      <td>0.496912</td>\n",
       "      <td>0.335822</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>76381.0</td>\n",
       "      <td>1.233174</td>\n",
       "      <td>-0.784851</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.698559</td>\n",
       "      <td>-1.034018</td>\n",
       "      <td>-0.637028</td>\n",
       "      <td>-0.502369</td>\n",
       "      <td>-0.188057</td>\n",
       "      <td>-0.749637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.234522</td>\n",
       "      <td>-0.059544</td>\n",
       "      <td>-0.109073</td>\n",
       "      <td>0.290326</td>\n",
       "      <td>-0.393074</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.038588</td>\n",
       "      <td>113.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1        V2         V3        V4         V5  \\\n",
       "43428    41505.0 -16.526507  8.584972 -18.649853  9.505594 -13.793819   \n",
       "49906    44261.0   0.339812 -2.743745  -0.134070 -1.385729  -1.451413   \n",
       "29474    35484.0   1.399590 -0.590701   0.168619 -1.029950  -0.539806   \n",
       "276481  167123.0  -0.432071  1.647895  -1.669361 -0.349504   0.785785   \n",
       "278846  168473.0   2.014160 -0.137394  -1.015839  0.327269  -0.182179   \n",
       "...          ...        ...       ...        ...       ...        ...   \n",
       "119879   75618.0   1.173488  0.100792   0.490512  0.461596  -0.296377   \n",
       "259178  159000.0  -0.775981  0.144023  -1.142399 -1.241113   1.940358   \n",
       "131932   79795.0  -0.146609  0.992946   1.524591  0.485774   0.349308   \n",
       "146867   87931.0  -2.948638  2.354849  -2.521201 -3.798905   1.866302   \n",
       "121958   76381.0   1.233174 -0.784851   0.386784 -0.698559  -1.034018   \n",
       "\n",
       "              V6         V7        V8        V9  ...       V21       V22  \\\n",
       "43428  -2.832404 -16.701694  7.517344 -8.507059  ...  1.190739 -1.127670   \n",
       "49906   1.015887  -0.524379  0.224060  0.899746  ... -0.213436 -0.942525   \n",
       "29474   0.040444  -0.712567  0.002299 -0.971747  ...  0.102398  0.168269   \n",
       "276481 -0.630647   0.276990  0.586025 -0.484715  ...  0.358932  0.873663   \n",
       "278846 -0.956571   0.043241 -0.160746  0.363241  ... -0.238644 -0.616400   \n",
       "...          ...        ...       ...       ...  ...       ...       ...   \n",
       "119879 -0.213165  -0.165254  0.119221 -0.114199  ... -0.186027 -0.574283   \n",
       "259178  3.912076  -0.466107  1.360620  0.400697  ...  0.037078 -0.019575   \n",
       "131932 -0.815198   1.076640 -0.395316 -0.491303  ...  0.052649  0.354089   \n",
       "146867  2.727695  -0.471769  2.217537  0.580199  ... -0.332759 -1.047514   \n",
       "121958 -0.637028  -0.502369 -0.188057 -0.749637  ...  0.027634 -0.234522   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "43428  -2.358579  0.673461 -1.413700 -0.462762 -2.018575 -1.042804  364.19   \n",
       "49906  -0.526819 -1.156992  0.311211 -0.746647  0.040996  0.102038  520.12   \n",
       "29474  -0.166639 -0.810250  0.505083 -0.232340  0.011409  0.004634   31.00   \n",
       "276481 -0.178642 -0.017171 -0.207392 -0.157756 -0.237386  0.001934    1.50   \n",
       "278846  0.347045  0.061561 -0.360196  0.174730 -0.078043 -0.070571    0.89   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "119879  0.161405 -0.006140  0.091444  0.109235 -0.020922  0.003967    1.98   \n",
       "259178  0.241830  0.682820 -1.635109 -0.770941  0.066006  0.137056   89.23   \n",
       "131932 -0.291198  0.402849  0.237383 -0.398467 -0.121139 -0.196195    3.94   \n",
       "146867  0.143326  0.678869  0.319710  0.426309  0.496912  0.335822    1.00   \n",
       "121958 -0.059544 -0.109073  0.290326 -0.393074  0.001217  0.038588  113.00   \n",
       "\n",
       "        Class  \n",
       "43428       1  \n",
       "49906       0  \n",
       "29474       0  \n",
       "276481      0  \n",
       "278846      0  \n",
       "...       ...  \n",
       "119879      0  \n",
       "259178      0  \n",
       "131932      0  \n",
       "146867      0  \n",
       "121958      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffled = data.sample(frac=1,random_state=42) \n",
    "data_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a6dc2",
   "metadata": {},
   "source": [
    " 1. Randomly shuffle the dataset by taking a random seed of “42”. Create a testing set from the last 20% rows of the dataframe (these must be the same for all the students). The remaining rows will be the training + validation set, with training : validation ratio of 80% : 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db21da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213180</th>\n",
       "      <td>139142.0</td>\n",
       "      <td>1.832595</td>\n",
       "      <td>-0.584732</td>\n",
       "      <td>-0.819403</td>\n",
       "      <td>-0.149297</td>\n",
       "      <td>0.329139</td>\n",
       "      <td>1.313078</td>\n",
       "      <td>-0.593704</td>\n",
       "      <td>0.446035</td>\n",
       "      <td>1.045166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298464</td>\n",
       "      <td>-0.616808</td>\n",
       "      <td>0.415845</td>\n",
       "      <td>-1.659516</td>\n",
       "      <td>-0.647589</td>\n",
       "      <td>-0.304438</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>-0.062264</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.948896</td>\n",
       "      <td>0.248414</td>\n",
       "      <td>2.956914</td>\n",
       "      <td>2.813750</td>\n",
       "      <td>0.145539</td>\n",
       "      <td>-0.027353</td>\n",
       "      <td>0.133702</td>\n",
       "      <td>-0.307535</td>\n",
       "      <td>-0.125244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083647</td>\n",
       "      <td>0.416090</td>\n",
       "      <td>0.207537</td>\n",
       "      <td>0.716064</td>\n",
       "      <td>-0.602311</td>\n",
       "      <td>-0.064230</td>\n",
       "      <td>-0.315058</td>\n",
       "      <td>-0.272463</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32212</th>\n",
       "      <td>36690.0</td>\n",
       "      <td>-0.584534</td>\n",
       "      <td>0.516797</td>\n",
       "      <td>2.690273</td>\n",
       "      <td>1.666086</td>\n",
       "      <td>-0.497783</td>\n",
       "      <td>0.712059</td>\n",
       "      <td>0.238978</td>\n",
       "      <td>0.218306</td>\n",
       "      <td>0.836184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400695</td>\n",
       "      <td>-0.460325</td>\n",
       "      <td>-0.017198</td>\n",
       "      <td>0.375110</td>\n",
       "      <td>-0.138729</td>\n",
       "      <td>-0.416343</td>\n",
       "      <td>0.268763</td>\n",
       "      <td>-0.034817</td>\n",
       "      <td>29.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139298</th>\n",
       "      <td>83093.0</td>\n",
       "      <td>1.003421</td>\n",
       "      <td>0.193060</td>\n",
       "      <td>1.620985</td>\n",
       "      <td>2.690939</td>\n",
       "      <td>-0.543496</td>\n",
       "      <td>0.913447</td>\n",
       "      <td>-0.657412</td>\n",
       "      <td>0.385481</td>\n",
       "      <td>-0.010028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.243906</td>\n",
       "      <td>0.133628</td>\n",
       "      <td>0.100668</td>\n",
       "      <td>0.123590</td>\n",
       "      <td>-0.006763</td>\n",
       "      <td>0.079287</td>\n",
       "      <td>0.034553</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270149</th>\n",
       "      <td>163938.0</td>\n",
       "      <td>-0.236620</td>\n",
       "      <td>1.154627</td>\n",
       "      <td>-0.528508</td>\n",
       "      <td>-0.853377</td>\n",
       "      <td>0.848756</td>\n",
       "      <td>-0.221496</td>\n",
       "      <td>0.622917</td>\n",
       "      <td>0.336601</td>\n",
       "      <td>-0.319941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257840</td>\n",
       "      <td>-0.676206</td>\n",
       "      <td>0.058260</td>\n",
       "      <td>-0.010006</td>\n",
       "      <td>-0.328057</td>\n",
       "      <td>0.155501</td>\n",
       "      <td>0.125989</td>\n",
       "      <td>0.035221</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>75618.0</td>\n",
       "      <td>1.173488</td>\n",
       "      <td>0.100792</td>\n",
       "      <td>0.490512</td>\n",
       "      <td>0.461596</td>\n",
       "      <td>-0.296377</td>\n",
       "      <td>-0.213165</td>\n",
       "      <td>-0.165254</td>\n",
       "      <td>0.119221</td>\n",
       "      <td>-0.114199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186027</td>\n",
       "      <td>-0.574283</td>\n",
       "      <td>0.161405</td>\n",
       "      <td>-0.006140</td>\n",
       "      <td>0.091444</td>\n",
       "      <td>0.109235</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>159000.0</td>\n",
       "      <td>-0.775981</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>-1.142399</td>\n",
       "      <td>-1.241113</td>\n",
       "      <td>1.940358</td>\n",
       "      <td>3.912076</td>\n",
       "      <td>-0.466107</td>\n",
       "      <td>1.360620</td>\n",
       "      <td>0.400697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037078</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>0.682820</td>\n",
       "      <td>-1.635109</td>\n",
       "      <td>-0.770941</td>\n",
       "      <td>0.066006</td>\n",
       "      <td>0.137056</td>\n",
       "      <td>89.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>79795.0</td>\n",
       "      <td>-0.146609</td>\n",
       "      <td>0.992946</td>\n",
       "      <td>1.524591</td>\n",
       "      <td>0.485774</td>\n",
       "      <td>0.349308</td>\n",
       "      <td>-0.815198</td>\n",
       "      <td>1.076640</td>\n",
       "      <td>-0.395316</td>\n",
       "      <td>-0.491303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052649</td>\n",
       "      <td>0.354089</td>\n",
       "      <td>-0.291198</td>\n",
       "      <td>0.402849</td>\n",
       "      <td>0.237383</td>\n",
       "      <td>-0.398467</td>\n",
       "      <td>-0.121139</td>\n",
       "      <td>-0.196195</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>87931.0</td>\n",
       "      <td>-2.948638</td>\n",
       "      <td>2.354849</td>\n",
       "      <td>-2.521201</td>\n",
       "      <td>-3.798905</td>\n",
       "      <td>1.866302</td>\n",
       "      <td>2.727695</td>\n",
       "      <td>-0.471769</td>\n",
       "      <td>2.217537</td>\n",
       "      <td>0.580199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332759</td>\n",
       "      <td>-1.047514</td>\n",
       "      <td>0.143326</td>\n",
       "      <td>0.678869</td>\n",
       "      <td>0.319710</td>\n",
       "      <td>0.426309</td>\n",
       "      <td>0.496912</td>\n",
       "      <td>0.335822</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>76381.0</td>\n",
       "      <td>1.233174</td>\n",
       "      <td>-0.784851</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.698559</td>\n",
       "      <td>-1.034018</td>\n",
       "      <td>-0.637028</td>\n",
       "      <td>-0.502369</td>\n",
       "      <td>-0.188057</td>\n",
       "      <td>-0.749637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027634</td>\n",
       "      <td>-0.234522</td>\n",
       "      <td>-0.059544</td>\n",
       "      <td>-0.109073</td>\n",
       "      <td>0.290326</td>\n",
       "      <td>-0.393074</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.038588</td>\n",
       "      <td>113.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "213180  139142.0  1.832595 -0.584732 -0.819403 -0.149297  0.329139  1.313078   \n",
       "67          44.0 -0.948896  0.248414  2.956914  2.813750  0.145539 -0.027353   \n",
       "32212    36690.0 -0.584534  0.516797  2.690273  1.666086 -0.497783  0.712059   \n",
       "139298   83093.0  1.003421  0.193060  1.620985  2.690939 -0.543496  0.913447   \n",
       "270149  163938.0 -0.236620  1.154627 -0.528508 -0.853377  0.848756 -0.221496   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "119879   75618.0  1.173488  0.100792  0.490512  0.461596 -0.296377 -0.213165   \n",
       "259178  159000.0 -0.775981  0.144023 -1.142399 -1.241113  1.940358  3.912076   \n",
       "131932   79795.0 -0.146609  0.992946  1.524591  0.485774  0.349308 -0.815198   \n",
       "146867   87931.0 -2.948638  2.354849 -2.521201 -3.798905  1.866302  2.727695   \n",
       "121958   76381.0  1.233174 -0.784851  0.386784 -0.698559 -1.034018 -0.637028   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "213180 -0.593704  0.446035  1.045166  ... -0.298464 -0.616808  0.415845   \n",
       "67      0.133702 -0.307535 -0.125244  ... -0.083647  0.416090  0.207537   \n",
       "32212   0.238978  0.218306  0.836184  ... -0.400695 -0.460325 -0.017198   \n",
       "139298 -0.657412  0.385481 -0.010028  ...  0.001964  0.243906  0.133628   \n",
       "270149  0.622917  0.336601 -0.319941  ... -0.257840 -0.676206  0.058260   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "119879 -0.165254  0.119221 -0.114199  ... -0.186027 -0.574283  0.161405   \n",
       "259178 -0.466107  1.360620  0.400697  ...  0.037078 -0.019575  0.241830   \n",
       "131932  1.076640 -0.395316 -0.491303  ...  0.052649  0.354089 -0.291198   \n",
       "146867 -0.471769  2.217537  0.580199  ... -0.332759 -1.047514  0.143326   \n",
       "121958 -0.502369 -0.188057 -0.749637  ...  0.027634 -0.234522 -0.059544   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "213180 -1.659516 -0.647589 -0.304438  0.044485 -0.062264   30.00      0  \n",
       "67      0.716064 -0.602311 -0.064230 -0.315058 -0.272463    0.75      0  \n",
       "32212   0.375110 -0.138729 -0.416343  0.268763 -0.034817   29.45      0  \n",
       "139298  0.100668  0.123590 -0.006763  0.079287  0.034553    6.47      0  \n",
       "270149 -0.010006 -0.328057  0.155501  0.125989  0.035221    1.98      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "119879 -0.006140  0.091444  0.109235 -0.020922  0.003967    1.98      0  \n",
       "259178  0.682820 -1.635109 -0.770941  0.066006  0.137056   89.23      0  \n",
       "131932  0.402849  0.237383 -0.398467 -0.121139 -0.196195    3.94      0  \n",
       "146867  0.678869  0.319710  0.426309  0.496912  0.335822    1.00      0  \n",
       "121958 -0.109073  0.290326 -0.393074  0.001217  0.038588  113.00      0  \n",
       "\n",
       "[56962 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data_shuffled.tail(56962)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b006c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TV=data_shuffled.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2cf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TV.sample(frac=0.8,random_state=42)\n",
    "TV = TV.drop(train.index)\n",
    "validation = TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92dc59a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96376</th>\n",
       "      <td>65743.0</td>\n",
       "      <td>1.302477</td>\n",
       "      <td>-0.866397</td>\n",
       "      <td>0.785250</td>\n",
       "      <td>-0.597110</td>\n",
       "      <td>-1.518418</td>\n",
       "      <td>-0.499402</td>\n",
       "      <td>-0.994682</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>-0.275751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228542</td>\n",
       "      <td>-0.283978</td>\n",
       "      <td>-0.010913</td>\n",
       "      <td>0.052434</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>1.128502</td>\n",
       "      <td>-0.036148</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35345</th>\n",
       "      <td>38079.0</td>\n",
       "      <td>-1.031103</td>\n",
       "      <td>1.818406</td>\n",
       "      <td>0.136551</td>\n",
       "      <td>0.698094</td>\n",
       "      <td>-0.094033</td>\n",
       "      <td>-0.366810</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.693414</td>\n",
       "      <td>-0.883850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162482</td>\n",
       "      <td>0.384328</td>\n",
       "      <td>-0.167306</td>\n",
       "      <td>-0.419153</td>\n",
       "      <td>-0.018059</td>\n",
       "      <td>-0.276089</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.089207</td>\n",
       "      <td>13.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154874</th>\n",
       "      <td>103443.0</td>\n",
       "      <td>1.895993</td>\n",
       "      <td>-0.011263</td>\n",
       "      <td>-1.697574</td>\n",
       "      <td>0.535603</td>\n",
       "      <td>1.018850</td>\n",
       "      <td>0.184163</td>\n",
       "      <td>0.361167</td>\n",
       "      <td>-0.175396</td>\n",
       "      <td>1.694461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006438</td>\n",
       "      <td>0.578767</td>\n",
       "      <td>0.063445</td>\n",
       "      <td>-1.033252</td>\n",
       "      <td>0.192139</td>\n",
       "      <td>-0.121096</td>\n",
       "      <td>-0.012608</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224584</th>\n",
       "      <td>143870.0</td>\n",
       "      <td>0.053089</td>\n",
       "      <td>0.526993</td>\n",
       "      <td>1.286889</td>\n",
       "      <td>0.281747</td>\n",
       "      <td>-0.634208</td>\n",
       "      <td>0.134735</td>\n",
       "      <td>-0.868736</td>\n",
       "      <td>-1.569898</td>\n",
       "      <td>0.507947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.658080</td>\n",
       "      <td>0.036417</td>\n",
       "      <td>-0.339205</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>0.761358</td>\n",
       "      <td>0.882561</td>\n",
       "      <td>0.203204</td>\n",
       "      <td>0.223315</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>38302.0</td>\n",
       "      <td>-0.196442</td>\n",
       "      <td>0.184731</td>\n",
       "      <td>1.951985</td>\n",
       "      <td>2.008439</td>\n",
       "      <td>-0.044212</td>\n",
       "      <td>1.298077</td>\n",
       "      <td>-0.426111</td>\n",
       "      <td>0.526389</td>\n",
       "      <td>0.336384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255556</td>\n",
       "      <td>-0.299140</td>\n",
       "      <td>0.082896</td>\n",
       "      <td>-0.281839</td>\n",
       "      <td>-0.436925</td>\n",
       "      <td>-0.344782</td>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.053057</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135689</th>\n",
       "      <td>81359.0</td>\n",
       "      <td>-1.931266</td>\n",
       "      <td>-1.011780</td>\n",
       "      <td>-0.612234</td>\n",
       "      <td>-0.299611</td>\n",
       "      <td>-2.330982</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>3.265720</td>\n",
       "      <td>-0.010687</td>\n",
       "      <td>-0.526067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510387</td>\n",
       "      <td>0.207153</td>\n",
       "      <td>1.770508</td>\n",
       "      <td>0.381687</td>\n",
       "      <td>-0.152602</td>\n",
       "      <td>0.811349</td>\n",
       "      <td>-0.078503</td>\n",
       "      <td>0.216781</td>\n",
       "      <td>774.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170267</th>\n",
       "      <td>120101.0</td>\n",
       "      <td>2.036483</td>\n",
       "      <td>0.107383</td>\n",
       "      <td>-1.505696</td>\n",
       "      <td>0.547835</td>\n",
       "      <td>0.086360</td>\n",
       "      <td>-1.196662</td>\n",
       "      <td>0.139343</td>\n",
       "      <td>-0.220991</td>\n",
       "      <td>0.588743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340098</td>\n",
       "      <td>-0.920511</td>\n",
       "      <td>0.413173</td>\n",
       "      <td>1.028598</td>\n",
       "      <td>-0.356345</td>\n",
       "      <td>0.142460</td>\n",
       "      <td>-0.067796</td>\n",
       "      <td>-0.026925</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267464</th>\n",
       "      <td>162784.0</td>\n",
       "      <td>1.762345</td>\n",
       "      <td>-0.845320</td>\n",
       "      <td>0.597132</td>\n",
       "      <td>0.702579</td>\n",
       "      <td>-1.642481</td>\n",
       "      <td>-0.298154</td>\n",
       "      <td>-1.217215</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>1.415258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325413</td>\n",
       "      <td>0.920293</td>\n",
       "      <td>0.262379</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>-0.669432</td>\n",
       "      <td>0.274798</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>-0.027950</td>\n",
       "      <td>59.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126976</th>\n",
       "      <td>78165.0</td>\n",
       "      <td>-0.463816</td>\n",
       "      <td>1.393423</td>\n",
       "      <td>2.264570</td>\n",
       "      <td>3.267127</td>\n",
       "      <td>0.265986</td>\n",
       "      <td>0.238790</td>\n",
       "      <td>0.696579</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>-1.505531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205537</td>\n",
       "      <td>-0.571200</td>\n",
       "      <td>-0.044516</td>\n",
       "      <td>0.333909</td>\n",
       "      <td>-0.107701</td>\n",
       "      <td>-0.227733</td>\n",
       "      <td>0.058558</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>11.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90781</th>\n",
       "      <td>63163.0</td>\n",
       "      <td>-1.528847</td>\n",
       "      <td>1.395167</td>\n",
       "      <td>1.036683</td>\n",
       "      <td>-1.780135</td>\n",
       "      <td>-0.218597</td>\n",
       "      <td>-0.671574</td>\n",
       "      <td>0.619586</td>\n",
       "      <td>-0.130388</td>\n",
       "      <td>1.607924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380982</td>\n",
       "      <td>-0.449695</td>\n",
       "      <td>-0.047731</td>\n",
       "      <td>-0.036520</td>\n",
       "      <td>-0.050484</td>\n",
       "      <td>0.703309</td>\n",
       "      <td>0.462506</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182276 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "96376    65743.0  1.302477 -0.866397  0.785250 -0.597110 -1.518418 -0.499402   \n",
       "35345    38079.0 -1.031103  1.818406  0.136551  0.698094 -0.094033 -0.366810   \n",
       "154874  103443.0  1.895993 -0.011263 -1.697574  0.535603  1.018850  0.184163   \n",
       "224584  143870.0  0.053089  0.526993  1.286889  0.281747 -0.634208  0.134735   \n",
       "35871    38302.0 -0.196442  0.184731  1.951985  2.008439 -0.044212  1.298077   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "135689   81359.0 -1.931266 -1.011780 -0.612234 -0.299611 -2.330982  0.000028   \n",
       "170267  120101.0  2.036483  0.107383 -1.505696  0.547835  0.086360 -1.196662   \n",
       "267464  162784.0  1.762345 -0.845320  0.597132  0.702579 -1.642481 -0.298154   \n",
       "126976   78165.0 -0.463816  1.393423  2.264570  3.267127  0.265986  0.238790   \n",
       "90781    63163.0 -1.528847  1.395167  1.036683 -1.780135 -0.218597 -0.671574   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "96376  -0.994682  0.001884 -0.275751  ... -0.228542 -0.283978 -0.010913   \n",
       "35345   0.159960  0.693414 -0.883850  ...  0.162482  0.384328 -0.167306   \n",
       "154874  0.361167 -0.175396  1.694461  ... -0.006438  0.578767  0.063445   \n",
       "224584 -0.868736 -1.569898  0.507947  ...  1.658080  0.036417 -0.339205   \n",
       "35871  -0.426111  0.526389  0.336384  ... -0.255556 -0.299140  0.082896   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "135689  3.265720 -0.010687 -0.526067  ...  0.510387  0.207153  1.770508   \n",
       "170267  0.139343 -0.220991  0.588743  ... -0.340098 -0.920511  0.413173   \n",
       "267464 -1.217215  0.273943  1.415258  ...  0.325413  0.920293  0.262379   \n",
       "126976  0.696579  0.118520 -1.505531  ... -0.205537 -0.571200 -0.044516   \n",
       "90781   0.619586 -0.130388  1.607924  ... -0.380982 -0.449695 -0.047731   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "96376   0.052434  0.073435  1.128502 -0.036148  0.021291   48.00      0  \n",
       "35345  -0.419153 -0.018059 -0.276089  0.040598  0.089207   13.95      0  \n",
       "154874 -1.033252  0.192139 -0.121096 -0.012608 -0.080000   33.00      0  \n",
       "224584  0.062116  0.761358  0.882561  0.203204  0.223315   11.50      0  \n",
       "35871  -0.281839 -0.436925 -0.344782  0.172683  0.053057   14.95      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "135689  0.381687 -0.152602  0.811349 -0.078503  0.216781  774.93      0  \n",
       "170267  1.028598 -0.356345  0.142460 -0.067796 -0.026925    2.58      0  \n",
       "267464  0.553398 -0.669432  0.274798  0.006122 -0.027950   59.90      0  \n",
       "126976  0.333909 -0.107701 -0.227733  0.058558  0.071475   11.34      0  \n",
       "90781  -0.036520 -0.050484  0.703309  0.462506 -0.035049    0.46      0  \n",
       "\n",
       "[182276 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b482eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101565</th>\n",
       "      <td>67878.0</td>\n",
       "      <td>-0.641330</td>\n",
       "      <td>-0.057304</td>\n",
       "      <td>1.489998</td>\n",
       "      <td>-1.688131</td>\n",
       "      <td>-1.151043</td>\n",
       "      <td>0.259996</td>\n",
       "      <td>-1.391069</td>\n",
       "      <td>-2.334075</td>\n",
       "      <td>1.168644</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.231634</td>\n",
       "      <td>0.257164</td>\n",
       "      <td>-0.371953</td>\n",
       "      <td>-0.038566</td>\n",
       "      <td>1.397514</td>\n",
       "      <td>-0.665947</td>\n",
       "      <td>0.031003</td>\n",
       "      <td>0.180357</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134976</th>\n",
       "      <td>81055.0</td>\n",
       "      <td>-1.593002</td>\n",
       "      <td>0.756803</td>\n",
       "      <td>1.274002</td>\n",
       "      <td>0.244127</td>\n",
       "      <td>0.335045</td>\n",
       "      <td>0.272886</td>\n",
       "      <td>0.389542</td>\n",
       "      <td>0.676944</td>\n",
       "      <td>-0.579539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031681</td>\n",
       "      <td>-0.063355</td>\n",
       "      <td>-0.268928</td>\n",
       "      <td>-0.321186</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>-0.390287</td>\n",
       "      <td>-0.195158</td>\n",
       "      <td>-0.039483</td>\n",
       "      <td>43.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246697</th>\n",
       "      <td>153290.0</td>\n",
       "      <td>-3.608205</td>\n",
       "      <td>-1.471144</td>\n",
       "      <td>0.327140</td>\n",
       "      <td>0.149964</td>\n",
       "      <td>3.666915</td>\n",
       "      <td>-2.701360</td>\n",
       "      <td>-1.340508</td>\n",
       "      <td>-0.522986</td>\n",
       "      <td>1.115929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746814</td>\n",
       "      <td>-0.033316</td>\n",
       "      <td>-1.690792</td>\n",
       "      <td>1.249015</td>\n",
       "      <td>-0.608078</td>\n",
       "      <td>0.326580</td>\n",
       "      <td>0.991899</td>\n",
       "      <td>-0.059786</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68279</th>\n",
       "      <td>52913.0</td>\n",
       "      <td>0.676855</td>\n",
       "      <td>1.587029</td>\n",
       "      <td>-1.508147</td>\n",
       "      <td>1.443815</td>\n",
       "      <td>1.316790</td>\n",
       "      <td>-1.160342</td>\n",
       "      <td>1.149049</td>\n",
       "      <td>-0.419393</td>\n",
       "      <td>-0.090565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191418</td>\n",
       "      <td>0.101451</td>\n",
       "      <td>0.058298</td>\n",
       "      <td>-0.135311</td>\n",
       "      <td>-0.604406</td>\n",
       "      <td>-0.452763</td>\n",
       "      <td>0.046430</td>\n",
       "      <td>-0.383642</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26525</th>\n",
       "      <td>34118.0</td>\n",
       "      <td>1.453447</td>\n",
       "      <td>-0.974690</td>\n",
       "      <td>-0.134962</td>\n",
       "      <td>-1.418547</td>\n",
       "      <td>-1.057755</td>\n",
       "      <td>-0.948851</td>\n",
       "      <td>-0.461141</td>\n",
       "      <td>-0.350840</td>\n",
       "      <td>-2.149149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556625</td>\n",
       "      <td>-1.398363</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>-0.177538</td>\n",
       "      <td>0.290735</td>\n",
       "      <td>-0.504811</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>76.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139747</th>\n",
       "      <td>83329.0</td>\n",
       "      <td>-2.654861</td>\n",
       "      <td>-2.573636</td>\n",
       "      <td>2.982088</td>\n",
       "      <td>0.177964</td>\n",
       "      <td>0.196961</td>\n",
       "      <td>-0.464111</td>\n",
       "      <td>-0.467951</td>\n",
       "      <td>0.247670</td>\n",
       "      <td>1.446265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158013</td>\n",
       "      <td>0.104976</td>\n",
       "      <td>0.650700</td>\n",
       "      <td>0.476358</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>1.031481</td>\n",
       "      <td>-0.059338</td>\n",
       "      <td>-0.041721</td>\n",
       "      <td>284.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218891</th>\n",
       "      <td>141514.0</td>\n",
       "      <td>-1.266761</td>\n",
       "      <td>0.567688</td>\n",
       "      <td>-1.137906</td>\n",
       "      <td>1.140781</td>\n",
       "      <td>0.687028</td>\n",
       "      <td>-0.672608</td>\n",
       "      <td>0.229731</td>\n",
       "      <td>0.582142</td>\n",
       "      <td>-0.896083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529202</td>\n",
       "      <td>1.416237</td>\n",
       "      <td>0.357878</td>\n",
       "      <td>0.650359</td>\n",
       "      <td>-0.822816</td>\n",
       "      <td>-0.499649</td>\n",
       "      <td>0.094544</td>\n",
       "      <td>-0.153482</td>\n",
       "      <td>6.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160717</th>\n",
       "      <td>113577.0</td>\n",
       "      <td>-0.406916</td>\n",
       "      <td>0.495423</td>\n",
       "      <td>-0.222752</td>\n",
       "      <td>-0.790593</td>\n",
       "      <td>0.824570</td>\n",
       "      <td>-1.255726</td>\n",
       "      <td>1.245641</td>\n",
       "      <td>-0.229602</td>\n",
       "      <td>0.276791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027158</td>\n",
       "      <td>-0.066620</td>\n",
       "      <td>0.205440</td>\n",
       "      <td>-0.136297</td>\n",
       "      <td>-0.761071</td>\n",
       "      <td>-0.340946</td>\n",
       "      <td>0.185565</td>\n",
       "      <td>0.269985</td>\n",
       "      <td>84.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281540</th>\n",
       "      <td>170250.0</td>\n",
       "      <td>-3.296875</td>\n",
       "      <td>2.924985</td>\n",
       "      <td>-2.237114</td>\n",
       "      <td>-0.999462</td>\n",
       "      <td>-0.247988</td>\n",
       "      <td>-1.252690</td>\n",
       "      <td>0.063705</td>\n",
       "      <td>0.683266</td>\n",
       "      <td>1.594078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.280853</td>\n",
       "      <td>-0.069211</td>\n",
       "      <td>0.613813</td>\n",
       "      <td>0.330438</td>\n",
       "      <td>0.590084</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>0.648336</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166978</th>\n",
       "      <td>118418.0</td>\n",
       "      <td>0.039574</td>\n",
       "      <td>0.747010</td>\n",
       "      <td>0.098041</td>\n",
       "      <td>-0.806212</td>\n",
       "      <td>0.615727</td>\n",
       "      <td>-0.548374</td>\n",
       "      <td>0.838212</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>-0.136691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251461</td>\n",
       "      <td>-0.619013</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>-0.523766</td>\n",
       "      <td>-0.486633</td>\n",
       "      <td>0.153365</td>\n",
       "      <td>0.237510</td>\n",
       "      <td>0.080317</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "101565   67878.0 -0.641330 -0.057304  1.489998 -1.688131 -1.151043  0.259996   \n",
       "134976   81055.0 -1.593002  0.756803  1.274002  0.244127  0.335045  0.272886   \n",
       "246697  153290.0 -3.608205 -1.471144  0.327140  0.149964  3.666915 -2.701360   \n",
       "68279    52913.0  0.676855  1.587029 -1.508147  1.443815  1.316790 -1.160342   \n",
       "26525    34118.0  1.453447 -0.974690 -0.134962 -1.418547 -1.057755 -0.948851   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139747   83329.0 -2.654861 -2.573636  2.982088  0.177964  0.196961 -0.464111   \n",
       "218891  141514.0 -1.266761  0.567688 -1.137906  1.140781  0.687028 -0.672608   \n",
       "160717  113577.0 -0.406916  0.495423 -0.222752 -0.790593  0.824570 -1.255726   \n",
       "281540  170250.0 -3.296875  2.924985 -2.237114 -0.999462 -0.247988 -1.252690   \n",
       "166978  118418.0  0.039574  0.747010  0.098041 -0.806212  0.615727 -0.548374   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "101565 -1.391069 -2.334075  1.168644  ... -1.231634  0.257164 -0.371953   \n",
       "134976  0.389542  0.676944 -0.579539  ...  0.031681 -0.063355 -0.268928   \n",
       "246697 -1.340508 -0.522986  1.115929  ... -0.746814 -0.033316 -1.690792   \n",
       "68279   1.149049 -0.419393 -0.090565  ... -0.191418  0.101451  0.058298   \n",
       "26525  -0.461141 -0.350840 -2.149149  ... -0.556625 -1.398363  0.089571   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "139747 -0.467951  0.247670  1.446265  ...  0.158013  0.104976  0.650700   \n",
       "218891  0.229731  0.582142 -0.896083  ...  0.529202  1.416237  0.357878   \n",
       "160717  1.245641 -0.229602  0.276791  ... -0.027158 -0.066620  0.205440   \n",
       "281540  0.063705  0.683266  1.594078  ...  0.046986  0.280853 -0.069211   \n",
       "166978  0.838212  0.020500 -0.136691  ... -0.251461 -0.619013  0.005320   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "101565 -0.038566  1.397514 -0.665947  0.031003  0.180357  100.00      0  \n",
       "134976 -0.321186  0.681500 -0.390287 -0.195158 -0.039483   43.50      0  \n",
       "246697  1.249015 -0.608078  0.326580  0.991899 -0.059786    8.54      0  \n",
       "68279  -0.135311 -0.604406 -0.452763  0.046430 -0.383642    0.89      0  \n",
       "26525  -0.177538  0.290735 -0.504811 -0.000739  0.025708   76.00      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "139747  0.476358  0.522876  1.031481 -0.059338 -0.041721  284.14      0  \n",
       "218891  0.650359 -0.822816 -0.499649  0.094544 -0.153482    6.17      0  \n",
       "160717 -0.136297 -0.761071 -0.340946  0.185565  0.269985   84.65      0  \n",
       "281540  0.613813  0.330438  0.590084  0.103159  0.648336    6.00      0  \n",
       "166978 -0.523766 -0.486633  0.153365  0.237510  0.080317    1.98      0  \n",
       "\n",
       "[45569 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5f840",
   "metadata": {},
   "source": [
    "Determine A) number of rows in training, validation and test sets, along with the structure, datatypes and value counts of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42bfe91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 56962 entries, 213180 to 121958\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    56962 non-null  float64\n",
      " 1   V1      56962 non-null  float64\n",
      " 2   V2      56962 non-null  float64\n",
      " 3   V3      56962 non-null  float64\n",
      " 4   V4      56962 non-null  float64\n",
      " 5   V5      56962 non-null  float64\n",
      " 6   V6      56962 non-null  float64\n",
      " 7   V7      56962 non-null  float64\n",
      " 8   V8      56962 non-null  float64\n",
      " 9   V9      56962 non-null  float64\n",
      " 10  V10     56962 non-null  float64\n",
      " 11  V11     56962 non-null  float64\n",
      " 12  V12     56962 non-null  float64\n",
      " 13  V13     56962 non-null  float64\n",
      " 14  V14     56962 non-null  float64\n",
      " 15  V15     56962 non-null  float64\n",
      " 16  V16     56962 non-null  float64\n",
      " 17  V17     56962 non-null  float64\n",
      " 18  V18     56962 non-null  float64\n",
      " 19  V19     56962 non-null  float64\n",
      " 20  V20     56962 non-null  float64\n",
      " 21  V21     56962 non-null  float64\n",
      " 22  V22     56962 non-null  float64\n",
      " 23  V23     56962 non-null  float64\n",
      " 24  V24     56962 non-null  float64\n",
      " 25  V25     56962 non-null  float64\n",
      " 26  V26     56962 non-null  float64\n",
      " 27  V27     56962 non-null  float64\n",
      " 28  V28     56962 non-null  float64\n",
      " 29  Amount  56962 non-null  float64\n",
      " 30  Class   56962 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 13.9 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf3f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 182276 entries, 96376 to 90781\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    182276 non-null  float64\n",
      " 1   V1      182276 non-null  float64\n",
      " 2   V2      182276 non-null  float64\n",
      " 3   V3      182276 non-null  float64\n",
      " 4   V4      182276 non-null  float64\n",
      " 5   V5      182276 non-null  float64\n",
      " 6   V6      182276 non-null  float64\n",
      " 7   V7      182276 non-null  float64\n",
      " 8   V8      182276 non-null  float64\n",
      " 9   V9      182276 non-null  float64\n",
      " 10  V10     182276 non-null  float64\n",
      " 11  V11     182276 non-null  float64\n",
      " 12  V12     182276 non-null  float64\n",
      " 13  V13     182276 non-null  float64\n",
      " 14  V14     182276 non-null  float64\n",
      " 15  V15     182276 non-null  float64\n",
      " 16  V16     182276 non-null  float64\n",
      " 17  V17     182276 non-null  float64\n",
      " 18  V18     182276 non-null  float64\n",
      " 19  V19     182276 non-null  float64\n",
      " 20  V20     182276 non-null  float64\n",
      " 21  V21     182276 non-null  float64\n",
      " 22  V22     182276 non-null  float64\n",
      " 23  V23     182276 non-null  float64\n",
      " 24  V24     182276 non-null  float64\n",
      " 25  V25     182276 non-null  float64\n",
      " 26  V26     182276 non-null  float64\n",
      " 27  V27     182276 non-null  float64\n",
      " 28  V28     182276 non-null  float64\n",
      " 29  Amount  182276 non-null  float64\n",
      " 30  Class   182276 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 44.5 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2401721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45569 entries, 101565 to 166978\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    45569 non-null  float64\n",
      " 1   V1      45569 non-null  float64\n",
      " 2   V2      45569 non-null  float64\n",
      " 3   V3      45569 non-null  float64\n",
      " 4   V4      45569 non-null  float64\n",
      " 5   V5      45569 non-null  float64\n",
      " 6   V6      45569 non-null  float64\n",
      " 7   V7      45569 non-null  float64\n",
      " 8   V8      45569 non-null  float64\n",
      " 9   V9      45569 non-null  float64\n",
      " 10  V10     45569 non-null  float64\n",
      " 11  V11     45569 non-null  float64\n",
      " 12  V12     45569 non-null  float64\n",
      " 13  V13     45569 non-null  float64\n",
      " 14  V14     45569 non-null  float64\n",
      " 15  V15     45569 non-null  float64\n",
      " 16  V16     45569 non-null  float64\n",
      " 17  V17     45569 non-null  float64\n",
      " 18  V18     45569 non-null  float64\n",
      " 19  V19     45569 non-null  float64\n",
      " 20  V20     45569 non-null  float64\n",
      " 21  V21     45569 non-null  float64\n",
      " 22  V22     45569 non-null  float64\n",
      " 23  V23     45569 non-null  float64\n",
      " 24  V24     45569 non-null  float64\n",
      " 25  V25     45569 non-null  float64\n",
      " 26  V26     45569 non-null  float64\n",
      " 27  V27     45569 non-null  float64\n",
      " 28  V28     45569 non-null  float64\n",
      " 29  Amount  45569 non-null  float64\n",
      " 30  Class   45569 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 11.1 MB\n"
     ]
    }
   ],
   "source": [
    "validation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360b61b",
   "metadata": {},
   "source": [
    " Analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e6caed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "614975f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aecdb4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a6a3d",
   "metadata": {},
   "source": [
    "Check for missing values and logically impute the dataset. Normalize the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29fd54fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213180</th>\n",
       "      <td>139142.0</td>\n",
       "      <td>0.989427</td>\n",
       "      <td>0.761089</td>\n",
       "      <td>0.909200</td>\n",
       "      <td>0.232791</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.276222</td>\n",
       "      <td>0.261739</td>\n",
       "      <td>0.684297</td>\n",
       "      <td>0.607508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503367</td>\n",
       "      <td>0.535930</td>\n",
       "      <td>0.495516</td>\n",
       "      <td>0.150605</td>\n",
       "      <td>0.495268</td>\n",
       "      <td>0.374774</td>\n",
       "      <td>0.232969</td>\n",
       "      <td>0.311860</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.942173</td>\n",
       "      <td>0.769879</td>\n",
       "      <td>0.981473</td>\n",
       "      <td>0.367584</td>\n",
       "      <td>0.766696</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.266170</td>\n",
       "      <td>0.671868</td>\n",
       "      <td>0.558012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508173</td>\n",
       "      <td>0.589588</td>\n",
       "      <td>0.490764</td>\n",
       "      <td>0.473760</td>\n",
       "      <td>0.498784</td>\n",
       "      <td>0.415145</td>\n",
       "      <td>0.224233</td>\n",
       "      <td>0.307595</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32212</th>\n",
       "      <td>36690.0</td>\n",
       "      <td>0.948363</td>\n",
       "      <td>0.772711</td>\n",
       "      <td>0.976370</td>\n",
       "      <td>0.315375</td>\n",
       "      <td>0.762365</td>\n",
       "      <td>0.270179</td>\n",
       "      <td>0.266811</td>\n",
       "      <td>0.680541</td>\n",
       "      <td>0.598671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501079</td>\n",
       "      <td>0.544059</td>\n",
       "      <td>0.485637</td>\n",
       "      <td>0.427380</td>\n",
       "      <td>0.534781</td>\n",
       "      <td>0.355966</td>\n",
       "      <td>0.238418</td>\n",
       "      <td>0.312417</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139298</th>\n",
       "      <td>83093.0</td>\n",
       "      <td>0.975341</td>\n",
       "      <td>0.769295</td>\n",
       "      <td>0.955905</td>\n",
       "      <td>0.361998</td>\n",
       "      <td>0.762058</td>\n",
       "      <td>0.272204</td>\n",
       "      <td>0.261350</td>\n",
       "      <td>0.683298</td>\n",
       "      <td>0.562884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510088</td>\n",
       "      <td>0.580643</td>\n",
       "      <td>0.489078</td>\n",
       "      <td>0.390047</td>\n",
       "      <td>0.555150</td>\n",
       "      <td>0.424804</td>\n",
       "      <td>0.233815</td>\n",
       "      <td>0.313825</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270149</th>\n",
       "      <td>163938.0</td>\n",
       "      <td>0.954274</td>\n",
       "      <td>0.779441</td>\n",
       "      <td>0.914767</td>\n",
       "      <td>0.200761</td>\n",
       "      <td>0.771430</td>\n",
       "      <td>0.260793</td>\n",
       "      <td>0.269150</td>\n",
       "      <td>0.682492</td>\n",
       "      <td>0.549778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504275</td>\n",
       "      <td>0.532844</td>\n",
       "      <td>0.487358</td>\n",
       "      <td>0.374991</td>\n",
       "      <td>0.520080</td>\n",
       "      <td>0.452075</td>\n",
       "      <td>0.234949</td>\n",
       "      <td>0.313839</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>75618.0</td>\n",
       "      <td>0.978230</td>\n",
       "      <td>0.768322</td>\n",
       "      <td>0.934270</td>\n",
       "      <td>0.260581</td>\n",
       "      <td>0.763721</td>\n",
       "      <td>0.260877</td>\n",
       "      <td>0.264349</td>\n",
       "      <td>0.678907</td>\n",
       "      <td>0.558479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.538139</td>\n",
       "      <td>0.489711</td>\n",
       "      <td>0.375517</td>\n",
       "      <td>0.552654</td>\n",
       "      <td>0.444299</td>\n",
       "      <td>0.231380</td>\n",
       "      <td>0.313204</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>159000.0</td>\n",
       "      <td>0.945111</td>\n",
       "      <td>0.768778</td>\n",
       "      <td>0.903018</td>\n",
       "      <td>0.183122</td>\n",
       "      <td>0.778779</td>\n",
       "      <td>0.302352</td>\n",
       "      <td>0.262516</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.580254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510874</td>\n",
       "      <td>0.566956</td>\n",
       "      <td>0.491546</td>\n",
       "      <td>0.469238</td>\n",
       "      <td>0.418587</td>\n",
       "      <td>0.296370</td>\n",
       "      <td>0.233492</td>\n",
       "      <td>0.315905</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>79795.0</td>\n",
       "      <td>0.955803</td>\n",
       "      <td>0.777735</td>\n",
       "      <td>0.954061</td>\n",
       "      <td>0.261681</td>\n",
       "      <td>0.768068</td>\n",
       "      <td>0.254824</td>\n",
       "      <td>0.271915</td>\n",
       "      <td>0.670420</td>\n",
       "      <td>0.542531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511222</td>\n",
       "      <td>0.586367</td>\n",
       "      <td>0.479386</td>\n",
       "      <td>0.431153</td>\n",
       "      <td>0.563986</td>\n",
       "      <td>0.358971</td>\n",
       "      <td>0.228945</td>\n",
       "      <td>0.309142</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>87931.0</td>\n",
       "      <td>0.908200</td>\n",
       "      <td>0.792106</td>\n",
       "      <td>0.876630</td>\n",
       "      <td>0.066764</td>\n",
       "      <td>0.778280</td>\n",
       "      <td>0.290444</td>\n",
       "      <td>0.262481</td>\n",
       "      <td>0.713514</td>\n",
       "      <td>0.587845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502599</td>\n",
       "      <td>0.513555</td>\n",
       "      <td>0.489299</td>\n",
       "      <td>0.468701</td>\n",
       "      <td>0.570379</td>\n",
       "      <td>0.497589</td>\n",
       "      <td>0.243962</td>\n",
       "      <td>0.319939</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>76381.0</td>\n",
       "      <td>0.979244</td>\n",
       "      <td>0.758977</td>\n",
       "      <td>0.932285</td>\n",
       "      <td>0.207804</td>\n",
       "      <td>0.758755</td>\n",
       "      <td>0.256615</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.673839</td>\n",
       "      <td>0.531606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510662</td>\n",
       "      <td>0.555789</td>\n",
       "      <td>0.484671</td>\n",
       "      <td>0.361515</td>\n",
       "      <td>0.568097</td>\n",
       "      <td>0.359877</td>\n",
       "      <td>0.231918</td>\n",
       "      <td>0.313907</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "213180  139142.0  0.989427  0.761089  0.909200  0.232791  0.767932  0.276222   \n",
       "67          44.0  0.942173  0.769879  0.981473  0.367584  0.766696  0.262745   \n",
       "32212    36690.0  0.948363  0.772711  0.976370  0.315375  0.762365  0.270179   \n",
       "139298   83093.0  0.975341  0.769295  0.955905  0.361998  0.762058  0.272204   \n",
       "270149  163938.0  0.954274  0.779441  0.914767  0.200761  0.771430  0.260793   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "119879   75618.0  0.978230  0.768322  0.934270  0.260581  0.763721  0.260877   \n",
       "259178  159000.0  0.945111  0.768778  0.903018  0.183122  0.778779  0.302352   \n",
       "131932   79795.0  0.955803  0.777735  0.954061  0.261681  0.768068  0.254824   \n",
       "146867   87931.0  0.908200  0.792106  0.876630  0.066764  0.778280  0.290444   \n",
       "121958   76381.0  0.979244  0.758977  0.932285  0.207804  0.758755  0.256615   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "213180  0.261739  0.684297  0.607508  ...  0.503367  0.535930  0.495516   \n",
       "67      0.266170  0.671868  0.558012  ...  0.508173  0.589588  0.490764   \n",
       "32212   0.266811  0.680541  0.598671  ...  0.501079  0.544059  0.485637   \n",
       "139298  0.261350  0.683298  0.562884  ...  0.510088  0.580643  0.489078   \n",
       "270149  0.269150  0.682492  0.549778  ...  0.504275  0.532844  0.487358   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "119879  0.264349  0.678907  0.558479  ...  0.505882  0.538139  0.489711   \n",
       "259178  0.262516  0.699381  0.580254  ...  0.510874  0.566956  0.491546   \n",
       "131932  0.271915  0.670420  0.542531  ...  0.511222  0.586367  0.479386   \n",
       "146867  0.262481  0.713514  0.587845  ...  0.502599  0.513555  0.489299   \n",
       "121958  0.262295  0.673839  0.531606  ...  0.510662  0.555789  0.484671   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "213180  0.150605  0.495268  0.374774  0.232969  0.311860  0.001168    0.0  \n",
       "67      0.473760  0.498784  0.415145  0.224233  0.307595  0.000029    0.0  \n",
       "32212   0.427380  0.534781  0.355966  0.238418  0.312417  0.001146    0.0  \n",
       "139298  0.390047  0.555150  0.424804  0.233815  0.313825  0.000252    0.0  \n",
       "270149  0.374991  0.520080  0.452075  0.234949  0.313839  0.000077    0.0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "119879  0.375517  0.552654  0.444299  0.231380  0.313204  0.000077    0.0  \n",
       "259178  0.469238  0.418587  0.296370  0.233492  0.315905  0.003473    0.0  \n",
       "131932  0.431153  0.563986  0.358971  0.228945  0.309142  0.000153    0.0  \n",
       "146867  0.468701  0.570379  0.497589  0.243962  0.319939  0.000039    0.0  \n",
       "121958  0.361515  0.568097  0.359877  0.231918  0.313907  0.004398    0.0  \n",
       "\n",
       "[56962 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# copy the data\n",
    "df_sklearn_test = test.copy()\n",
    "\n",
    "# apply normalization techniques\n",
    "column1 = 'V1'\n",
    "column2 = 'V2'\n",
    "column3 = 'V3'\n",
    "column4 = 'V4'\n",
    "column5 = 'V5'\n",
    "column6 = 'V6'\n",
    "column7 = 'V7'\n",
    "column8 = 'V8'\n",
    "column9 = 'V9'\n",
    "column10 = 'V10'\n",
    "column11 = 'V11'\n",
    "column12 = 'V12'\n",
    "column13 = 'V13'\n",
    "column14 = 'V14'\n",
    "column15 = 'V15'\n",
    "column16 = 'V16'\n",
    "column17 = 'V17'\n",
    "column18 = 'V18'\n",
    "column19 = 'V19'\n",
    "column20 = 'V20'\n",
    "column21 = 'V21'\n",
    "column22 = 'V22'\n",
    "column23 = 'V23'\n",
    "column24 = 'V24'\n",
    "column25 = 'V25'\n",
    "column26 = 'V26'\n",
    "column27 = 'V27'\n",
    "column28 = 'V28'\n",
    "column29 = 'Amount'\n",
    "column30 = 'Class'\n",
    "\n",
    "df_sklearn_test[column1] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column1]).reshape(-1,1))\n",
    "df_sklearn_test[column2] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column2]).reshape(-1,1))\n",
    "df_sklearn_test[column3] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column3]).reshape(-1,1))\n",
    "df_sklearn_test[column4] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column4]).reshape(-1,1))\n",
    "df_sklearn_test[column5] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column5]).reshape(-1,1))\n",
    "df_sklearn_test[column6] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column6]).reshape(-1,1))\n",
    "df_sklearn_test[column7] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column7]).reshape(-1,1))\n",
    "df_sklearn_test[column8] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column8]).reshape(-1,1))\n",
    "df_sklearn_test[column9] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column9]).reshape(-1,1))\n",
    "df_sklearn_test[column10] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column10]).reshape(-1,1))\n",
    "df_sklearn_test[column11] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column11]).reshape(-1,1))\n",
    "df_sklearn_test[column12] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column12]).reshape(-1,1))\n",
    "df_sklearn_test[column13] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column13]).reshape(-1,1))\n",
    "df_sklearn_test[column14] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column14]).reshape(-1,1))\n",
    "df_sklearn_test[column15] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column15]).reshape(-1,1))\n",
    "df_sklearn_test[column16] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column16]).reshape(-1,1))\n",
    "df_sklearn_test[column17] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column17]).reshape(-1,1))\n",
    "df_sklearn_test[column18] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column18]).reshape(-1,1))\n",
    "df_sklearn_test[column19] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column19]).reshape(-1,1))\n",
    "df_sklearn_test[column20] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column20]).reshape(-1,1))\n",
    "df_sklearn_test[column21] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column21]).reshape(-1,1))\n",
    "df_sklearn_test[column22] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column22]).reshape(-1,1))\n",
    "df_sklearn_test[column23] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column23]).reshape(-1,1))\n",
    "df_sklearn_test[column24] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column24]).reshape(-1,1))\n",
    "df_sklearn_test[column25] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column25]).reshape(-1,1))\n",
    "df_sklearn_test[column26] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column26]).reshape(-1,1))\n",
    "df_sklearn_test[column27] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column27]).reshape(-1,1))\n",
    "df_sklearn_test[column28] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column28]).reshape(-1,1))\n",
    "df_sklearn_test[column29] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column29]).reshape(-1,1))\n",
    "df_sklearn_test[column30] = MinMaxScaler().fit_transform(np.array(df_sklearn_test[column30]).reshape(-1,1))\n",
    "\n",
    "# view normalized data\n",
    "display(df_sklearn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e275f6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96376</th>\n",
       "      <td>65743.0</td>\n",
       "      <td>0.976795</td>\n",
       "      <td>0.727412</td>\n",
       "      <td>0.800358</td>\n",
       "      <td>0.225461</td>\n",
       "      <td>0.541273</td>\n",
       "      <td>0.459396</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.785406</td>\n",
       "      <td>0.453281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557795</td>\n",
       "      <td>0.460714</td>\n",
       "      <td>0.699558</td>\n",
       "      <td>0.421578</td>\n",
       "      <td>0.582029</td>\n",
       "      <td>0.609787</td>\n",
       "      <td>0.681195</td>\n",
       "      <td>0.341738</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35345</th>\n",
       "      <td>38079.0</td>\n",
       "      <td>0.929463</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.785294</td>\n",
       "      <td>0.282876</td>\n",
       "      <td>0.561088</td>\n",
       "      <td>0.462332</td>\n",
       "      <td>0.486982</td>\n",
       "      <td>0.792824</td>\n",
       "      <td>0.432333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564099</td>\n",
       "      <td>0.494125</td>\n",
       "      <td>0.697116</td>\n",
       "      <td>0.352763</td>\n",
       "      <td>0.576893</td>\n",
       "      <td>0.380350</td>\n",
       "      <td>0.683515</td>\n",
       "      <td>0.343716</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154874</th>\n",
       "      <td>103443.0</td>\n",
       "      <td>0.988834</td>\n",
       "      <td>0.737850</td>\n",
       "      <td>0.742703</td>\n",
       "      <td>0.275673</td>\n",
       "      <td>0.576570</td>\n",
       "      <td>0.474530</td>\n",
       "      <td>0.489333</td>\n",
       "      <td>0.783504</td>\n",
       "      <td>0.521151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561376</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.700719</td>\n",
       "      <td>0.263152</td>\n",
       "      <td>0.588692</td>\n",
       "      <td>0.405668</td>\n",
       "      <td>0.681906</td>\n",
       "      <td>0.338787</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224584</th>\n",
       "      <td>143870.0</td>\n",
       "      <td>0.951454</td>\n",
       "      <td>0.744419</td>\n",
       "      <td>0.812006</td>\n",
       "      <td>0.264420</td>\n",
       "      <td>0.553574</td>\n",
       "      <td>0.473436</td>\n",
       "      <td>0.474959</td>\n",
       "      <td>0.768545</td>\n",
       "      <td>0.480278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588208</td>\n",
       "      <td>0.476732</td>\n",
       "      <td>0.694431</td>\n",
       "      <td>0.422991</td>\n",
       "      <td>0.620644</td>\n",
       "      <td>0.569613</td>\n",
       "      <td>0.688431</td>\n",
       "      <td>0.347622</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>38302.0</td>\n",
       "      <td>0.946392</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.340963</td>\n",
       "      <td>0.561781</td>\n",
       "      <td>0.499193</td>\n",
       "      <td>0.480132</td>\n",
       "      <td>0.791032</td>\n",
       "      <td>0.474368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557360</td>\n",
       "      <td>0.459956</td>\n",
       "      <td>0.701023</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>0.553381</td>\n",
       "      <td>0.369129</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>0.342663</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135689</th>\n",
       "      <td>81359.0</td>\n",
       "      <td>0.911204</td>\n",
       "      <td>0.725638</td>\n",
       "      <td>0.767906</td>\n",
       "      <td>0.238649</td>\n",
       "      <td>0.529970</td>\n",
       "      <td>0.470454</td>\n",
       "      <td>0.523280</td>\n",
       "      <td>0.785271</td>\n",
       "      <td>0.444658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569707</td>\n",
       "      <td>0.485268</td>\n",
       "      <td>0.727377</td>\n",
       "      <td>0.469623</td>\n",
       "      <td>0.569341</td>\n",
       "      <td>0.557981</td>\n",
       "      <td>0.679914</td>\n",
       "      <td>0.347432</td>\n",
       "      <td>0.040980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170267</th>\n",
       "      <td>120101.0</td>\n",
       "      <td>0.991683</td>\n",
       "      <td>0.739298</td>\n",
       "      <td>0.747158</td>\n",
       "      <td>0.276215</td>\n",
       "      <td>0.563598</td>\n",
       "      <td>0.443958</td>\n",
       "      <td>0.486741</td>\n",
       "      <td>0.783015</td>\n",
       "      <td>0.483061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555997</td>\n",
       "      <td>0.428892</td>\n",
       "      <td>0.706181</td>\n",
       "      <td>0.564022</td>\n",
       "      <td>0.557904</td>\n",
       "      <td>0.448719</td>\n",
       "      <td>0.680238</td>\n",
       "      <td>0.340333</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267464</th>\n",
       "      <td>162784.0</td>\n",
       "      <td>0.986123</td>\n",
       "      <td>0.727670</td>\n",
       "      <td>0.795989</td>\n",
       "      <td>0.283075</td>\n",
       "      <td>0.539547</td>\n",
       "      <td>0.463852</td>\n",
       "      <td>0.470886</td>\n",
       "      <td>0.788324</td>\n",
       "      <td>0.511533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566725</td>\n",
       "      <td>0.520920</td>\n",
       "      <td>0.703826</td>\n",
       "      <td>0.494680</td>\n",
       "      <td>0.540330</td>\n",
       "      <td>0.470336</td>\n",
       "      <td>0.682473</td>\n",
       "      <td>0.340303</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126976</th>\n",
       "      <td>78165.0</td>\n",
       "      <td>0.940969</td>\n",
       "      <td>0.754994</td>\n",
       "      <td>0.834710</td>\n",
       "      <td>0.396759</td>\n",
       "      <td>0.566096</td>\n",
       "      <td>0.475740</td>\n",
       "      <td>0.493253</td>\n",
       "      <td>0.786657</td>\n",
       "      <td>0.410917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558166</td>\n",
       "      <td>0.446355</td>\n",
       "      <td>0.699033</td>\n",
       "      <td>0.462651</td>\n",
       "      <td>0.571861</td>\n",
       "      <td>0.388249</td>\n",
       "      <td>0.684058</td>\n",
       "      <td>0.343199</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90781</th>\n",
       "      <td>63163.0</td>\n",
       "      <td>0.919367</td>\n",
       "      <td>0.755015</td>\n",
       "      <td>0.806196</td>\n",
       "      <td>0.173018</td>\n",
       "      <td>0.559355</td>\n",
       "      <td>0.455584</td>\n",
       "      <td>0.492353</td>\n",
       "      <td>0.783987</td>\n",
       "      <td>0.518170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555338</td>\n",
       "      <td>0.452430</td>\n",
       "      <td>0.698983</td>\n",
       "      <td>0.408598</td>\n",
       "      <td>0.575073</td>\n",
       "      <td>0.540333</td>\n",
       "      <td>0.696272</td>\n",
       "      <td>0.340097</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182276 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "96376    65743.0  0.976795  0.727412  0.800358  0.225461  0.541273  0.459396   \n",
       "35345    38079.0  0.929463  0.760181  0.785294  0.282876  0.561088  0.462332   \n",
       "154874  103443.0  0.988834  0.737850  0.742703  0.275673  0.576570  0.474530   \n",
       "224584  143870.0  0.951454  0.744419  0.812006  0.264420  0.553574  0.473436   \n",
       "35871    38302.0  0.946392  0.740242  0.827451  0.340963  0.561781  0.499193   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "135689   81359.0  0.911204  0.725638  0.767906  0.238649  0.529970  0.470454   \n",
       "170267  120101.0  0.991683  0.739298  0.747158  0.276215  0.563598  0.443958   \n",
       "267464  162784.0  0.986123  0.727670  0.795989  0.283075  0.539547  0.463852   \n",
       "126976   78165.0  0.940969  0.754994  0.834710  0.396759  0.566096  0.475740   \n",
       "90781    63163.0  0.919367  0.755015  0.806196  0.173018  0.559355  0.455584   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "96376   0.473487  0.785406  0.453281  ...  0.557795  0.460714  0.699558   \n",
       "35345   0.486982  0.792824  0.432333  ...  0.564099  0.494125  0.697116   \n",
       "154874  0.489333  0.783504  0.521151  ...  0.561376  0.503846  0.700719   \n",
       "224584  0.474959  0.768545  0.480278  ...  0.588208  0.476732  0.694431   \n",
       "35871   0.480132  0.791032  0.474368  ...  0.557360  0.459956  0.701023   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "135689  0.523280  0.785271  0.444658  ...  0.569707  0.485268  0.727377   \n",
       "170267  0.486741  0.783015  0.483061  ...  0.555997  0.428892  0.706181   \n",
       "267464  0.470886  0.788324  0.511533  ...  0.566725  0.520920  0.703826   \n",
       "126976  0.493253  0.786657  0.410917  ...  0.558166  0.446355  0.699033   \n",
       "90781   0.492353  0.783987  0.518170  ...  0.555338  0.452430  0.698983   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "96376   0.421578  0.582029  0.609787  0.681195  0.341738  0.002538    0.0  \n",
       "35345   0.352763  0.576893  0.380350  0.683515  0.343716  0.000738    0.0  \n",
       "154874  0.263152  0.588692  0.405668  0.681906  0.338787  0.001745    0.0  \n",
       "224584  0.422991  0.620644  0.569613  0.688431  0.347622  0.000608    0.0  \n",
       "35871   0.372800  0.553381  0.369129  0.687509  0.342663  0.000791    0.0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "135689  0.469623  0.569341  0.557981  0.679914  0.347432  0.040980    0.0  \n",
       "170267  0.564022  0.557904  0.448719  0.680238  0.340333  0.000136    0.0  \n",
       "267464  0.494680  0.540330  0.470336  0.682473  0.340303  0.003168    0.0  \n",
       "126976  0.462651  0.571861  0.388249  0.684058  0.343199  0.000600    0.0  \n",
       "90781   0.408598  0.575073  0.540333  0.696272  0.340097  0.000024    0.0  \n",
       "\n",
       "[182276 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# copy the data\n",
    "df_sklearn_train = train.copy()\n",
    "\n",
    "# apply normalization techniques\n",
    "column1 = 'V1'\n",
    "column2 = 'V2'\n",
    "column3 = 'V3'\n",
    "column4 = 'V4'\n",
    "column5 = 'V5'\n",
    "column6 = 'V6'\n",
    "column7 = 'V7'\n",
    "column8 = 'V8'\n",
    "column9 = 'V9'\n",
    "column10 = 'V10'\n",
    "column11 = 'V11'\n",
    "column12 = 'V12'\n",
    "column13 = 'V13'\n",
    "column14 = 'V14'\n",
    "column15 = 'V15'\n",
    "column16 = 'V16'\n",
    "column17 = 'V17'\n",
    "column18 = 'V18'\n",
    "column19 = 'V19'\n",
    "column20 = 'V20'\n",
    "column21 = 'V21'\n",
    "column22 = 'V22'\n",
    "column23 = 'V23'\n",
    "column24 = 'V24'\n",
    "column25 = 'V25'\n",
    "column26 = 'V26'\n",
    "column27 = 'V27'\n",
    "column28 = 'V28'\n",
    "column29 = 'Amount'\n",
    "column30 = 'Class'\n",
    "\n",
    "df_sklearn_train[column1] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column1]).reshape(-1,1))\n",
    "df_sklearn_train[column2] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column2]).reshape(-1,1))\n",
    "df_sklearn_train[column3] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column3]).reshape(-1,1))\n",
    "df_sklearn_train[column4] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column4]).reshape(-1,1))\n",
    "df_sklearn_train[column5] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column5]).reshape(-1,1))\n",
    "df_sklearn_train[column6] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column6]).reshape(-1,1))\n",
    "df_sklearn_train[column7] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column7]).reshape(-1,1))\n",
    "df_sklearn_train[column8] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column8]).reshape(-1,1))\n",
    "df_sklearn_train[column9] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column9]).reshape(-1,1))\n",
    "df_sklearn_train[column10] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column10]).reshape(-1,1))\n",
    "df_sklearn_train[column11] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column11]).reshape(-1,1))\n",
    "df_sklearn_train[column12] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column12]).reshape(-1,1))\n",
    "df_sklearn_train[column13] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column13]).reshape(-1,1))\n",
    "df_sklearn_train[column14] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column14]).reshape(-1,1))\n",
    "df_sklearn_train[column15] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column15]).reshape(-1,1))\n",
    "df_sklearn_train[column16] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column16]).reshape(-1,1))\n",
    "df_sklearn_train[column17] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column17]).reshape(-1,1))\n",
    "df_sklearn_train[column18] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column18]).reshape(-1,1))\n",
    "df_sklearn_train[column19] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column19]).reshape(-1,1))\n",
    "df_sklearn_train[column20] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column20]).reshape(-1,1))\n",
    "df_sklearn_train[column21] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column21]).reshape(-1,1))\n",
    "df_sklearn_train[column22] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column22]).reshape(-1,1))\n",
    "df_sklearn_train[column23] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column23]).reshape(-1,1))\n",
    "df_sklearn_train[column24] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column24]).reshape(-1,1))\n",
    "df_sklearn_train[column25] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column25]).reshape(-1,1))\n",
    "df_sklearn_train[column26] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column26]).reshape(-1,1))\n",
    "df_sklearn_train[column27] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column27]).reshape(-1,1))\n",
    "df_sklearn_train[column28] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column28]).reshape(-1,1))\n",
    "df_sklearn_train[column29] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column29]).reshape(-1,1))\n",
    "df_sklearn_train[column30] = MinMaxScaler().fit_transform(np.array(df_sklearn_train[column30]).reshape(-1,1))\n",
    "\n",
    "# view normalized data\n",
    "display(df_sklearn_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc9cede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101565</th>\n",
       "      <td>67878.0</td>\n",
       "      <td>0.912657</td>\n",
       "      <td>0.670372</td>\n",
       "      <td>0.929541</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>0.537683</td>\n",
       "      <td>0.516158</td>\n",
       "      <td>0.455518</td>\n",
       "      <td>0.637038</td>\n",
       "      <td>0.601910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379240</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>0.465582</td>\n",
       "      <td>0.406705</td>\n",
       "      <td>0.605829</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.448982</td>\n",
       "      <td>0.380552</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134976</th>\n",
       "      <td>81055.0</td>\n",
       "      <td>0.885785</td>\n",
       "      <td>0.685083</td>\n",
       "      <td>0.923714</td>\n",
       "      <td>0.362241</td>\n",
       "      <td>0.557174</td>\n",
       "      <td>0.516438</td>\n",
       "      <td>0.480986</td>\n",
       "      <td>0.688973</td>\n",
       "      <td>0.514304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406820</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.468033</td>\n",
       "      <td>0.365420</td>\n",
       "      <td>0.545437</td>\n",
       "      <td>0.275987</td>\n",
       "      <td>0.438702</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246697</th>\n",
       "      <td>153290.0</td>\n",
       "      <td>0.828882</td>\n",
       "      <td>0.644822</td>\n",
       "      <td>0.898169</td>\n",
       "      <td>0.356365</td>\n",
       "      <td>0.600872</td>\n",
       "      <td>0.451817</td>\n",
       "      <td>0.456241</td>\n",
       "      <td>0.668276</td>\n",
       "      <td>0.599269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389825</td>\n",
       "      <td>0.555282</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>0.594795</td>\n",
       "      <td>0.436668</td>\n",
       "      <td>0.424005</td>\n",
       "      <td>0.492663</td>\n",
       "      <td>0.371225</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68279</th>\n",
       "      <td>52913.0</td>\n",
       "      <td>0.949879</td>\n",
       "      <td>0.700086</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>0.437114</td>\n",
       "      <td>0.570050</td>\n",
       "      <td>0.485299</td>\n",
       "      <td>0.491849</td>\n",
       "      <td>0.670063</td>\n",
       "      <td>0.538808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401950</td>\n",
       "      <td>0.563734</td>\n",
       "      <td>0.475821</td>\n",
       "      <td>0.392572</td>\n",
       "      <td>0.436977</td>\n",
       "      <td>0.263087</td>\n",
       "      <td>0.449684</td>\n",
       "      <td>0.358647</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26525</th>\n",
       "      <td>34118.0</td>\n",
       "      <td>0.971807</td>\n",
       "      <td>0.653794</td>\n",
       "      <td>0.885702</td>\n",
       "      <td>0.258474</td>\n",
       "      <td>0.538907</td>\n",
       "      <td>0.489894</td>\n",
       "      <td>0.468818</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>0.435647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393977</td>\n",
       "      <td>0.469670</td>\n",
       "      <td>0.476565</td>\n",
       "      <td>0.386404</td>\n",
       "      <td>0.512478</td>\n",
       "      <td>0.252340</td>\n",
       "      <td>0.447540</td>\n",
       "      <td>0.374546</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139747</th>\n",
       "      <td>83329.0</td>\n",
       "      <td>0.855801</td>\n",
       "      <td>0.624899</td>\n",
       "      <td>0.969795</td>\n",
       "      <td>0.358112</td>\n",
       "      <td>0.555363</td>\n",
       "      <td>0.500426</td>\n",
       "      <td>0.468721</td>\n",
       "      <td>0.681569</td>\n",
       "      <td>0.615823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409578</td>\n",
       "      <td>0.563955</td>\n",
       "      <td>0.489920</td>\n",
       "      <td>0.481925</td>\n",
       "      <td>0.532058</td>\n",
       "      <td>0.569551</td>\n",
       "      <td>0.444876</td>\n",
       "      <td>0.371927</td>\n",
       "      <td>0.032324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218891</th>\n",
       "      <td>141514.0</td>\n",
       "      <td>0.894997</td>\n",
       "      <td>0.681666</td>\n",
       "      <td>0.858645</td>\n",
       "      <td>0.418201</td>\n",
       "      <td>0.561790</td>\n",
       "      <td>0.495896</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>0.687338</td>\n",
       "      <td>0.498442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417682</td>\n",
       "      <td>0.646194</td>\n",
       "      <td>0.482951</td>\n",
       "      <td>0.507343</td>\n",
       "      <td>0.418556</td>\n",
       "      <td>0.253406</td>\n",
       "      <td>0.451871</td>\n",
       "      <td>0.367586</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160717</th>\n",
       "      <td>113577.0</td>\n",
       "      <td>0.919276</td>\n",
       "      <td>0.680360</td>\n",
       "      <td>0.883334</td>\n",
       "      <td>0.297665</td>\n",
       "      <td>0.563594</td>\n",
       "      <td>0.483226</td>\n",
       "      <td>0.493230</td>\n",
       "      <td>0.673336</td>\n",
       "      <td>0.557217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405536</td>\n",
       "      <td>0.553193</td>\n",
       "      <td>0.479323</td>\n",
       "      <td>0.392428</td>\n",
       "      <td>0.423763</td>\n",
       "      <td>0.286175</td>\n",
       "      <td>0.456009</td>\n",
       "      <td>0.384033</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281540</th>\n",
       "      <td>170250.0</td>\n",
       "      <td>0.837673</td>\n",
       "      <td>0.724264</td>\n",
       "      <td>0.828990</td>\n",
       "      <td>0.284629</td>\n",
       "      <td>0.549527</td>\n",
       "      <td>0.483292</td>\n",
       "      <td>0.476325</td>\n",
       "      <td>0.689082</td>\n",
       "      <td>0.623230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407154</td>\n",
       "      <td>0.574986</td>\n",
       "      <td>0.472787</td>\n",
       "      <td>0.502005</td>\n",
       "      <td>0.515826</td>\n",
       "      <td>0.478412</td>\n",
       "      <td>0.452263</td>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166978</th>\n",
       "      <td>118418.0</td>\n",
       "      <td>0.931884</td>\n",
       "      <td>0.684906</td>\n",
       "      <td>0.891988</td>\n",
       "      <td>0.296690</td>\n",
       "      <td>0.560855</td>\n",
       "      <td>0.498595</td>\n",
       "      <td>0.487403</td>\n",
       "      <td>0.677650</td>\n",
       "      <td>0.536497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400639</td>\n",
       "      <td>0.518549</td>\n",
       "      <td>0.474560</td>\n",
       "      <td>0.335827</td>\n",
       "      <td>0.446911</td>\n",
       "      <td>0.388239</td>\n",
       "      <td>0.458370</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "101565   67878.0  0.912657  0.670372  0.929541  0.241650  0.537683  0.516158   \n",
       "134976   81055.0  0.885785  0.685083  0.923714  0.362241  0.557174  0.516438   \n",
       "246697  153290.0  0.828882  0.644822  0.898169  0.356365  0.600872  0.451817   \n",
       "68279    52913.0  0.949879  0.700086  0.848656  0.437114  0.570050  0.485299   \n",
       "26525    34118.0  0.971807  0.653794  0.885702  0.258474  0.538907  0.489894   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139747   83329.0  0.855801  0.624899  0.969795  0.358112  0.555363  0.500426   \n",
       "218891  141514.0  0.894997  0.681666  0.858645  0.418201  0.561790  0.495896   \n",
       "160717  113577.0  0.919276  0.680360  0.883334  0.297665  0.563594  0.483226   \n",
       "281540  170250.0  0.837673  0.724264  0.828990  0.284629  0.549527  0.483292   \n",
       "166978  118418.0  0.931884  0.684906  0.891988  0.296690  0.560855  0.498595   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "101565  0.455518  0.637038  0.601910  ...  0.379240  0.573500  0.465582   \n",
       "134976  0.480986  0.688973  0.514304  ...  0.406820  0.553398  0.468033   \n",
       "246697  0.456241  0.668276  0.599269  ...  0.389825  0.555282  0.434195   \n",
       "68279   0.491849  0.670063  0.538808  ...  0.401950  0.563734  0.475821   \n",
       "26525   0.468818  0.671245  0.435647  ...  0.393977  0.469670  0.476565   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "139747  0.468721  0.681569  0.615823  ...  0.409578  0.563955  0.489920   \n",
       "218891  0.478700  0.687338  0.498442  ...  0.417682  0.646194  0.482951   \n",
       "160717  0.493230  0.673336  0.557217  ...  0.405536  0.553193  0.479323   \n",
       "281540  0.476325  0.689082  0.623230  ...  0.407154  0.574986  0.472787   \n",
       "166978  0.487403  0.677650  0.536497  ...  0.400639  0.518549  0.474560   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "101565  0.406705  0.605829  0.219069  0.448982  0.380552  0.011376    0.0  \n",
       "134976  0.365420  0.545437  0.275987  0.438702  0.372014  0.004949    0.0  \n",
       "246697  0.594795  0.436668  0.424005  0.492663  0.371225  0.000972    0.0  \n",
       "68279   0.392572  0.436977  0.263087  0.449684  0.358647  0.000101    0.0  \n",
       "26525   0.386404  0.512478  0.252340  0.447540  0.374546  0.008646    0.0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "139747  0.481925  0.532058  0.569551  0.444876  0.371927  0.032324    0.0  \n",
       "218891  0.507343  0.418556  0.253406  0.451871  0.367586  0.000702    0.0  \n",
       "160717  0.392428  0.423763  0.286175  0.456009  0.384033  0.009630    0.0  \n",
       "281540  0.502005  0.515826  0.478412  0.452263  0.398728  0.000683    0.0  \n",
       "166978  0.335827  0.446911  0.388239  0.458370  0.376667  0.000225    0.0  \n",
       "\n",
       "[45569 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# copy the data\n",
    "df_sklearn_validation = validation.copy()\n",
    "\n",
    "# apply normalization techniques\n",
    "column1 = 'V1'\n",
    "column2 = 'V2'\n",
    "column3 = 'V3'\n",
    "column4 = 'V4'\n",
    "column5 = 'V5'\n",
    "column6 = 'V6'\n",
    "column7 = 'V7'\n",
    "column8 = 'V8'\n",
    "column9 = 'V9'\n",
    "column10 = 'V10'\n",
    "column11 = 'V11'\n",
    "column12 = 'V12'\n",
    "column13 = 'V13'\n",
    "column14 = 'V14'\n",
    "column15 = 'V15'\n",
    "column16 = 'V16'\n",
    "column17 = 'V17'\n",
    "column18 = 'V18'\n",
    "column19 = 'V19'\n",
    "column20 = 'V20'\n",
    "column21 = 'V21'\n",
    "column22 = 'V22'\n",
    "column23 = 'V23'\n",
    "column24 = 'V24'\n",
    "column25 = 'V25'\n",
    "column26 = 'V26'\n",
    "column27 = 'V27'\n",
    "column28 = 'V28'\n",
    "column29 = 'Amount'\n",
    "column30 = 'Class'\n",
    "\n",
    "df_sklearn_validation[column1] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column1]).reshape(-1,1))\n",
    "df_sklearn_validation[column2] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column2]).reshape(-1,1))\n",
    "df_sklearn_validation[column3] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column3]).reshape(-1,1))\n",
    "df_sklearn_validation[column4] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column4]).reshape(-1,1))\n",
    "df_sklearn_validation[column5] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column5]).reshape(-1,1))\n",
    "df_sklearn_validation[column6] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column6]).reshape(-1,1))\n",
    "df_sklearn_validation[column7] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column7]).reshape(-1,1))\n",
    "df_sklearn_validation[column8] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column8]).reshape(-1,1))\n",
    "df_sklearn_validation[column9] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column9]).reshape(-1,1))\n",
    "df_sklearn_validation[column10] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column10]).reshape(-1,1))\n",
    "df_sklearn_validation[column11] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column11]).reshape(-1,1))\n",
    "df_sklearn_validation[column12] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column12]).reshape(-1,1))\n",
    "df_sklearn_validation[column13] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column13]).reshape(-1,1))\n",
    "df_sklearn_validation[column14] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column14]).reshape(-1,1))\n",
    "df_sklearn_validation[column15] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column15]).reshape(-1,1))\n",
    "df_sklearn_validation[column16] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column16]).reshape(-1,1))\n",
    "df_sklearn_validation[column17] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column17]).reshape(-1,1))\n",
    "df_sklearn_validation[column18] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column18]).reshape(-1,1))\n",
    "df_sklearn_validation[column19] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column19]).reshape(-1,1))\n",
    "df_sklearn_validation[column20] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column20]).reshape(-1,1))\n",
    "df_sklearn_validation[column21] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column21]).reshape(-1,1))\n",
    "df_sklearn_validation[column22] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column22]).reshape(-1,1))\n",
    "df_sklearn_validation[column23] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column23]).reshape(-1,1))\n",
    "df_sklearn_validation[column24] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column24]).reshape(-1,1))\n",
    "df_sklearn_validation[column25] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column25]).reshape(-1,1))\n",
    "df_sklearn_validation[column26] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column26]).reshape(-1,1))\n",
    "df_sklearn_validation[column27] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column27]).reshape(-1,1))\n",
    "df_sklearn_validation[column28] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column28]).reshape(-1,1))\n",
    "df_sklearn_validation[column29] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column29]).reshape(-1,1))\n",
    "df_sklearn_validation[column30] = MinMaxScaler().fit_transform(np.array(df_sklearn_validation[column30]).reshape(-1,1))\n",
    "\n",
    "# view normalized data\n",
    "display(df_sklearn_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ffc24",
   "metadata": {},
   "source": [
    "Train a logistic regression model on the training set partition by taking all the features. Calculate the error on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631bdb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shuffled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc7a78",
   "metadata": {},
   "source": [
    "Inference: The dataset is quite imbalanced as almost 99% of dataset lies in legit category.\n",
    "0: Legit Transaction 1: Fraudulent Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b15e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284315, 31) (492, 31)\n"
     ]
    }
   ],
   "source": [
    "legit = data_shuffled[data_shuffled.Class == 0]\n",
    "fraud = data_shuffled[data_shuffled.Class == 1]\n",
    "\n",
    "print(legit.shape, fraud.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb641a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>94786.851874</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.737902</td>\n",
       "      <td>0.782421</td>\n",
       "      <td>0.251635</td>\n",
       "      <td>0.562469</td>\n",
       "      <td>0.470492</td>\n",
       "      <td>0.485216</td>\n",
       "      <td>0.785391</td>\n",
       "      <td>0.462801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423583</td>\n",
       "      <td>0.561475</td>\n",
       "      <td>0.474818</td>\n",
       "      <td>0.699733</td>\n",
       "      <td>0.413937</td>\n",
       "      <td>0.577943</td>\n",
       "      <td>0.425424</td>\n",
       "      <td>0.682272</td>\n",
       "      <td>0.341112</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>80321.666667</td>\n",
       "      <td>0.844057</td>\n",
       "      <td>0.784061</td>\n",
       "      <td>0.611334</td>\n",
       "      <td>0.451870</td>\n",
       "      <td>0.516139</td>\n",
       "      <td>0.438491</td>\n",
       "      <td>0.416616</td>\n",
       "      <td>0.792648</td>\n",
       "      <td>0.371533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429463</td>\n",
       "      <td>0.572234</td>\n",
       "      <td>0.475829</td>\n",
       "      <td>0.698588</td>\n",
       "      <td>0.396059</td>\n",
       "      <td>0.581108</td>\n",
       "      <td>0.428535</td>\n",
       "      <td>0.686737</td>\n",
       "      <td>0.342829</td>\n",
       "      <td>0.006512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0.0    94786.851874  0.950667  0.737902  0.782421  0.251635  0.562469   \n",
       "1.0    80321.666667  0.844057  0.784061  0.611334  0.451870  0.516139   \n",
       "\n",
       "             V6        V7        V8        V9  ...       V20       V21  \\\n",
       "Class                                          ...                       \n",
       "0.0    0.470492  0.485216  0.785391  0.462801  ...  0.423583  0.561475   \n",
       "1.0    0.438491  0.416616  0.792648  0.371533  ...  0.429463  0.572234   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0.0    0.474818  0.699733  0.413937  0.577943  0.425424  0.682272  0.341112   \n",
       "1.0    0.475829  0.698588  0.396059  0.581108  0.428535  0.686737  0.342829   \n",
       "\n",
       "         Amount  \n",
       "Class            \n",
       "0.0    0.004654  \n",
       "1.0    0.006512  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sklearn_train.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a22c9",
   "metadata": {},
   "source": [
    "From the above data we can infer that the difference in the feature and average transaction amount are high for fraud transaction when compared to legit transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb1df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitSample = data_shuffled.sample(n=492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78b13b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202716</th>\n",
       "      <td>134457.0</td>\n",
       "      <td>1.793422</td>\n",
       "      <td>0.299002</td>\n",
       "      <td>-0.963626</td>\n",
       "      <td>3.422377</td>\n",
       "      <td>1.221984</td>\n",
       "      <td>1.837163</td>\n",
       "      <td>-0.173703</td>\n",
       "      <td>0.445799</td>\n",
       "      <td>-1.060098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379773</td>\n",
       "      <td>1.272053</td>\n",
       "      <td>-0.014857</td>\n",
       "      <td>-1.618795</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.355734</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>-0.078875</td>\n",
       "      <td>10.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86385</th>\n",
       "      <td>61210.0</td>\n",
       "      <td>-0.374056</td>\n",
       "      <td>0.954433</td>\n",
       "      <td>1.537871</td>\n",
       "      <td>0.921676</td>\n",
       "      <td>0.351973</td>\n",
       "      <td>-0.027871</td>\n",
       "      <td>1.308941</td>\n",
       "      <td>-0.588589</td>\n",
       "      <td>-0.339304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084832</td>\n",
       "      <td>0.656406</td>\n",
       "      <td>-0.242210</td>\n",
       "      <td>0.104150</td>\n",
       "      <td>-0.271291</td>\n",
       "      <td>-0.308618</td>\n",
       "      <td>-0.382551</td>\n",
       "      <td>-0.314940</td>\n",
       "      <td>60.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38437</th>\n",
       "      <td>39393.0</td>\n",
       "      <td>-0.564448</td>\n",
       "      <td>0.845147</td>\n",
       "      <td>-0.563832</td>\n",
       "      <td>-0.298278</td>\n",
       "      <td>-0.814236</td>\n",
       "      <td>-0.711808</td>\n",
       "      <td>-0.420679</td>\n",
       "      <td>0.557716</td>\n",
       "      <td>-2.229734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059764</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>0.228728</td>\n",
       "      <td>0.074576</td>\n",
       "      <td>-1.318135</td>\n",
       "      <td>1.064465</td>\n",
       "      <td>-0.321398</td>\n",
       "      <td>0.082395</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194610</th>\n",
       "      <td>130680.0</td>\n",
       "      <td>0.185564</td>\n",
       "      <td>1.164883</td>\n",
       "      <td>-1.046875</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.281740</td>\n",
       "      <td>-1.456382</td>\n",
       "      <td>0.629786</td>\n",
       "      <td>0.091832</td>\n",
       "      <td>-0.188164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329242</td>\n",
       "      <td>0.945124</td>\n",
       "      <td>-0.074683</td>\n",
       "      <td>-0.029147</td>\n",
       "      <td>-0.262192</td>\n",
       "      <td>-0.153192</td>\n",
       "      <td>-0.069167</td>\n",
       "      <td>-0.043434</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111564</th>\n",
       "      <td>72275.0</td>\n",
       "      <td>-0.755126</td>\n",
       "      <td>0.558822</td>\n",
       "      <td>1.159600</td>\n",
       "      <td>-1.622096</td>\n",
       "      <td>0.379060</td>\n",
       "      <td>-0.655795</td>\n",
       "      <td>0.888093</td>\n",
       "      <td>-0.530559</td>\n",
       "      <td>-1.535842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255245</td>\n",
       "      <td>-0.596393</td>\n",
       "      <td>-0.383195</td>\n",
       "      <td>-0.448010</td>\n",
       "      <td>0.475237</td>\n",
       "      <td>-0.431820</td>\n",
       "      <td>-0.115133</td>\n",
       "      <td>-0.121671</td>\n",
       "      <td>39.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42674</th>\n",
       "      <td>41194.0</td>\n",
       "      <td>-7.896886</td>\n",
       "      <td>5.381020</td>\n",
       "      <td>-8.451162</td>\n",
       "      <td>7.963928</td>\n",
       "      <td>-7.862419</td>\n",
       "      <td>-2.376820</td>\n",
       "      <td>-11.949723</td>\n",
       "      <td>5.051356</td>\n",
       "      <td>-6.912076</td>\n",
       "      <td>...</td>\n",
       "      <td>2.557944</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>0.638073</td>\n",
       "      <td>0.361887</td>\n",
       "      <td>0.444577</td>\n",
       "      <td>1.101923</td>\n",
       "      <td>0.205958</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33276</th>\n",
       "      <td>37167.0</td>\n",
       "      <td>-7.923891</td>\n",
       "      <td>-5.198360</td>\n",
       "      <td>-3.000024</td>\n",
       "      <td>4.420666</td>\n",
       "      <td>2.272194</td>\n",
       "      <td>-3.394483</td>\n",
       "      <td>-5.283435</td>\n",
       "      <td>0.131619</td>\n",
       "      <td>0.658176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.734308</td>\n",
       "      <td>-0.599926</td>\n",
       "      <td>-4.908301</td>\n",
       "      <td>0.410170</td>\n",
       "      <td>-1.167660</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>1.937421</td>\n",
       "      <td>-1.552593</td>\n",
       "      <td>12.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182992</th>\n",
       "      <td>125612.0</td>\n",
       "      <td>1.889618</td>\n",
       "      <td>1.073099</td>\n",
       "      <td>-1.678018</td>\n",
       "      <td>4.173268</td>\n",
       "      <td>1.015516</td>\n",
       "      <td>-0.009389</td>\n",
       "      <td>-0.079706</td>\n",
       "      <td>0.064071</td>\n",
       "      <td>-0.714517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203728</td>\n",
       "      <td>0.733796</td>\n",
       "      <td>-0.036560</td>\n",
       "      <td>0.334306</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>0.279556</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154697</th>\n",
       "      <td>102625.0</td>\n",
       "      <td>-4.221221</td>\n",
       "      <td>2.871121</td>\n",
       "      <td>-5.888716</td>\n",
       "      <td>6.890952</td>\n",
       "      <td>-3.404894</td>\n",
       "      <td>-1.154394</td>\n",
       "      <td>-7.739928</td>\n",
       "      <td>2.851363</td>\n",
       "      <td>-2.507569</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620591</td>\n",
       "      <td>1.567947</td>\n",
       "      <td>-0.578007</td>\n",
       "      <td>-0.059045</td>\n",
       "      <td>-1.829169</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>0.136734</td>\n",
       "      <td>-0.599848</td>\n",
       "      <td>7.59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226814</th>\n",
       "      <td>144808.0</td>\n",
       "      <td>-2.405207</td>\n",
       "      <td>2.943823</td>\n",
       "      <td>-7.616654</td>\n",
       "      <td>3.533374</td>\n",
       "      <td>-5.417494</td>\n",
       "      <td>-0.112632</td>\n",
       "      <td>-1.329372</td>\n",
       "      <td>1.709417</td>\n",
       "      <td>-2.322716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652683</td>\n",
       "      <td>0.414132</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>-0.260616</td>\n",
       "      <td>0.405316</td>\n",
       "      <td>0.029107</td>\n",
       "      <td>0.519807</td>\n",
       "      <td>-0.469537</td>\n",
       "      <td>667.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "202716  134457.0  1.793422  0.299002 -0.963626  3.422377  1.221984  1.837163   \n",
       "86385    61210.0 -0.374056  0.954433  1.537871  0.921676  0.351973 -0.027871   \n",
       "38437    39393.0 -0.564448  0.845147 -0.563832 -0.298278 -0.814236 -0.711808   \n",
       "194610  130680.0  0.185564  1.164883 -1.046875  0.010641  0.281740 -1.456382   \n",
       "111564   72275.0 -0.755126  0.558822  1.159600 -1.622096  0.379060 -0.655795   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "42674    41194.0 -7.896886  5.381020 -8.451162  7.963928 -7.862419 -2.376820   \n",
       "33276    37167.0 -7.923891 -5.198360 -3.000024  4.420666  2.272194 -3.394483   \n",
       "182992  125612.0  1.889618  1.073099 -1.678018  4.173268  1.015516 -0.009389   \n",
       "154697  102625.0 -4.221221  2.871121 -5.888716  6.890952 -3.404894 -1.154394   \n",
       "226814  144808.0 -2.405207  2.943823 -7.616654  3.533374 -5.417494 -0.112632   \n",
       "\n",
       "               V7        V8        V9  ...       V21       V22       V23  \\\n",
       "202716  -0.173703  0.445799 -1.060098  ...  0.379773  1.272053 -0.014857   \n",
       "86385    1.308941 -0.588589 -0.339304  ...  0.084832  0.656406 -0.242210   \n",
       "38437   -0.420679  0.557716 -2.229734  ... -0.059764  0.038882  0.228728   \n",
       "194610   0.629786  0.091832 -0.188164  ...  0.329242  0.945124 -0.074683   \n",
       "111564   0.888093 -0.530559 -1.535842  ... -0.255245 -0.596393 -0.383195   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "42674  -11.949723  5.051356 -6.912076  ...  2.557944  0.926278  0.032795   \n",
       "33276   -5.283435  0.131619  0.658176  ... -0.734308 -0.599926 -4.908301   \n",
       "182992  -0.079706  0.064071 -0.714517  ...  0.203728  0.733796 -0.036560   \n",
       "154697  -7.739928  2.851363 -2.507569  ...  1.620591  1.567947 -0.578007   \n",
       "226814  -1.329372  1.709417 -2.322716  ...  0.652683  0.414132  0.023869   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "202716 -1.618795  0.053356  0.355734  0.010487 -0.078875   10.62      0  \n",
       "86385   0.104150 -0.271291 -0.308618 -0.382551 -0.314940   60.98      0  \n",
       "38437   0.074576 -1.318135  1.064465 -0.321398  0.082395    8.50      0  \n",
       "194610 -0.029147 -0.262192 -0.153192 -0.069167 -0.043434   18.00      0  \n",
       "111564 -0.448010  0.475237 -0.431820 -0.115133 -0.121671   39.43      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "42674   0.638073  0.361887  0.444577  1.101923  0.205958    1.52      1  \n",
       "33276   0.410170 -1.167660  0.520508  1.937421 -1.552593   12.31      1  \n",
       "182992  0.334306  0.147171  0.279556  0.031669  0.035883    3.22      1  \n",
       "154697 -0.059045 -1.829169 -0.072429  0.136734 -0.599848    7.59      1  \n",
       "226814 -0.260616  0.405316  0.029107  0.519807 -0.469537  667.55      1  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.concat([legitSample,fraud],axis=0)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "023b486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_new.drop(columns=\"Class\",axis=1)\n",
    "Y=df_new[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f7cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 30) (787, 30) (197, 30)\n",
      "(984,) (787,) (197,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "print(X.shape, X_train.shape, X_test.shape)\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ae963b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelL = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b3f9901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelL.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7876ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787\n"
     ]
    }
   ],
   "source": [
    "trainPrediction= modelL.predict(X_train)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4450fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sklearn_test=df_sklearn_test.drop(columns=\"Class\",axis=1)\n",
    "testPrediction= modelL.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cf4d49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on training data is : 0.92\n"
     ]
    }
   ],
   "source": [
    "# Y_train = df_sklearn_train['Class']\n",
    "print(f\"The accuracy score on training data is : {round(accuracy_score(testPrediction, Y_test),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fea85ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix_train = confusion_matrix(Y_test, testPrediction)\n",
    "cm_display_train = ConfusionMatrixDisplay(cf_matrix_train).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad4cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on test data is : 0.95\n",
      "The recall on test data is : 0.89\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "precision_test = precision_score(Y_test, testPrediction)\n",
    "print(f\"The precision on test data is : {round(precision_test, 2)}\")\n",
    "# recall\n",
    "recall_test = recall_score(Y_test, testPrediction)\n",
    "print(f\"The recall on test data is : {round(recall_test, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5e4cc",
   "metadata": {},
   "source": [
    "Train a neural network model (MLPClassifier) by taking all the features and predicting the result. Fix the random_state for training. Choose the solver as ‘adam’, and set the number of hidden layers to (10, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75ae8865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(10, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMLP = MLPClassifier(solver='adam',hidden_layer_sizes=(10,2))\n",
    "modelMLP.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d05899a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictionMLP = modelMLP.predict(X_train)\n",
    "testPredictionMLP = modelMLP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43699ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on training data is : 0.5\n"
     ]
    }
   ],
   "source": [
    "# Y_train = df_sklearn_train['Class']\n",
    "print(f\"The accuracy score on training data is : {round(accuracy_score(testPredictionMLP, Y_test),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c66c3a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix_train = confusion_matrix(Y_test, testPredictionMLP)\n",
    "cm_display_train = ConfusionMatrixDisplay(cf_matrix_train).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559817a",
   "metadata": {},
   "source": [
    "Vary the hidden layers to find the best set of results on validation set. Explore different training parameters of MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35ee892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on test data is : 0.5\n",
      "The recall on test data is : 1.0\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "precision_test = precision_score(Y_test, testPredictionMLP)\n",
    "print(f\"The precision on test data is : {round(precision_test, 2)}\")\n",
    "# recall\n",
    "recall_test = recall_score(Y_test, testPredictionMLP)\n",
    "print(f\"The recall on test data is : {round(recall_test, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bebed3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on training data is : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelMLP = MLPClassifier(solver='adam',hidden_layer_sizes=(25,2),max_iter=25)\n",
    "modelMLP.fit(X_train,Y_train)\n",
    "testPredictionMLP = modelMLP.predict(X_test)\n",
    "# Y_train = df_sklearn_train['Class']\n",
    "print(f\"The accuracy score on training data is : {round(accuracy_score(testPredictionMLP, Y_test),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eaaaeed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix_train = confusion_matrix(Y_test, testPredictionMLP)\n",
    "cm_display_train = ConfusionMatrixDisplay(cf_matrix_train).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "246c97ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on test data is : 0.0\n",
      "The recall on test data is : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "precision_test = precision_score(Y_test, testPredictionMLP)\n",
    "print(f\"The precision on test data is : {round(precision_test, 2)}\")\n",
    "# recall\n",
    "recall_test = recall_score(Y_test, testPredictionMLP)\n",
    "print(f\"The recall on test data is : {round(recall_test, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a719b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on training data is : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modelMLP = MLPClassifier(solver='adam',hidden_layer_sizes=(50,2),max_iter=50)\n",
    "modelMLP.fit(X_train,Y_train)\n",
    "testPredictionMLP = modelMLP.predict(X_test)\n",
    "# Y_train = df_sklearn_train['Class']\n",
    "print(f\"The accuracy score on training data is : {round(accuracy_score(testPredictionMLP, Y_test),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef249167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix_train = confusion_matrix(Y_test, testPredictionMLP)\n",
    "cm_display_train = ConfusionMatrixDisplay(cf_matrix_train).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cb1c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on test data is : 0.0\n",
      "The recall on test data is : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "precision_test = precision_score(Y_test, testPredictionMLP)\n",
    "print(f\"The precision on test data is : {round(precision_test, 2)}\")\n",
    "# recall\n",
    "recall_test = recall_score(Y_test, testPredictionMLP)\n",
    "print(f\"The recall on test data is : {round(recall_test, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
